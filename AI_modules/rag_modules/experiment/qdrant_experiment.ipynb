{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:31:17.549082Z",
     "iopub.status.busy": "2025-04-28T13:31:17.548888Z",
     "iopub.status.idle": "2025-04-28T13:32:40.957230Z",
     "shell.execute_reply": "2025-04-28T13:32:40.956452Z",
     "shell.execute_reply.started": "2025-04-28T13:31:17.549065Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama_index\n",
      "  Downloading llama_index-0.12.33-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting qdrant-client\n",
      "  Downloading qdrant_client-1.14.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting llama-index-vector-stores-qdrant\n",
      "  Downloading llama_index_vector_stores_qdrant-0.6.0-py3-none-any.whl.metadata (718 bytes)\n",
      "Collecting llama_index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.5.3-py3-none-any.whl.metadata (767 bytes)\n",
      "Collecting cohere\n",
      "  Downloading cohere-5.15.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama_index)\n",
      "  Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl.metadata (727 bytes)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.1 (from llama_index)\n",
      "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.33 (from llama_index)\n",
      "  Downloading llama_index_core-0.12.33.post1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama_index)\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama_index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama_index)\n",
      "  Downloading llama_index_llms_openai-0.3.38-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama_index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama_index)\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama_index)\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama_index)\n",
      "  Downloading llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama_index)\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama_index) (3.9.1)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (1.70.0)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (1.26.4)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (3.20.3)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.11.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (0.30.2)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from llama_index-embeddings-huggingface) (3.4.1)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
      "  Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting httpx-sse==0.4.0 (from cohere)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.33.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.0)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
      "  Downloading types_requests-2.32.0.20250328-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (4.13.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (3.11.16)\n",
      "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.61.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.33->llama_index) (2.0.38)\n",
      "Collecting banks<3.0.0,>=2.0.0 (from llama-index-core<0.13.0,>=0.12.33->llama_index)\n",
      "  Downloading banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama_index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama_index) (1.2.18)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.33->llama_index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.33->llama_index)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama_index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama_index) (3.4.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama_index) (11.1.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama_index) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama_index) (0.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama_index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.33->llama_index) (1.17.2)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama_index)\n",
      "  Downloading llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5.0,>=0.4.0->llama_index)\n",
      "  Downloading openai-1.76.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (4.13.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (5.4.0)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
      "  Downloading llama_parse-0.6.16-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (2024.11.6)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (2.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (4.51.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (2.5.1+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (1.15.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (1.19.0)\n",
      "Collecting griffe (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.33->llama_index)\n",
      "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.33->llama_index) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.33->llama_index) (4.3.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.6)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Collecting llama-cloud-services>=0.6.16 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
      "  Downloading llama_cloud_services-0.6.17-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.3.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.33->llama_index) (3.1.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (0.5.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.33->llama_index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.33->llama_index) (3.26.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->qdrant-client) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->qdrant-client) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21->qdrant-client) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21->qdrant-client) (2024.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (3.6.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21->qdrant-client) (2024.2.0)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.16->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (1.17.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.33->llama_index) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.33->llama_index) (3.0.2)\n",
      "Downloading llama_index-0.12.33-py3-none-any.whl (7.0 kB)\n",
      "Downloading qdrant_client-1.14.2-py3-none-any.whl (327 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_vector_stores_qdrant-0.6.0-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_embeddings_huggingface-0.5.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading cohere-5.15.0-py3-none-any.whl (259 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.12.33.post1-py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\n",
      "Downloading llama_index_llms_openai-0.3.38-py3-none-any.whl (23 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading types_requests-2.32.0.20250328-py3-none-any.whl (20 kB)\n",
      "Downloading banks-2.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_cloud-0.1.19-py3-none-any.whl (263 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.6/263.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_parse-0.6.16-py3-none-any.whl (4.9 kB)\n",
      "Downloading openai-1.76.0-py3-none-any.whl (661 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.2/661.2 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_cloud_services-0.6.17-py3-none-any.whl (36 kB)\n",
      "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: striprtf, filetype, dirtyjson, types-requests, python-dotenv, portalocker, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, httpx-sse, griffe, fastavro, nvidia-cusparse-cu12, nvidia-cudnn-cu12, openai, nvidia-cusolver-cu12, llama-cloud, banks, cohere, llama-index-core, llama-index-llms-openai, llama-index-agent-openai, llama-cloud-services, llama-parse, llama-index-program-openai, llama-index-embeddings-openai, qdrant-client, llama-index-readers-llama-parse, llama-index-readers-file, llama-index-question-gen-openai, llama-index-multi-modal-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-cli, llama-index-vector-stores-qdrant, llama_index-embeddings-huggingface, llama_index\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.61.1\n",
      "    Uninstalling openai-1.61.1:\n",
      "      Successfully uninstalled openai-1.61.1\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed banks-2.1.2 cohere-5.15.0 dirtyjson-1.0.8 fastavro-1.10.0 filetype-1.2.0 griffe-1.7.3 httpx-sse-0.4.0 llama-cloud-0.1.19 llama-cloud-services-0.6.17 llama-index-agent-openai-0.4.6 llama-index-cli-0.4.1 llama-index-core-0.12.33.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-openai-0.3.38 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-index-vector-stores-qdrant-0.6.0 llama-parse-0.6.16 llama_index-0.12.33 llama_index-embeddings-huggingface-0.5.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-1.76.0 portalocker-2.10.1 python-dotenv-1.1.0 qdrant-client-1.14.2 striprtf-0.0.26 types-requests-2.32.0.20250328\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_index qdrant-client llama-index-vector-stores-qdrant llama_index-embeddings-huggingface cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:32:40.959222Z",
     "iopub.status.busy": "2025-04-28T13:32:40.959008Z",
     "iopub.status.idle": "2025-04-28T13:32:54.909798Z",
     "shell.execute_reply": "2025-04-28T13:32:54.909104Z",
     "shell.execute_reply.started": "2025-04-28T13:32:40.959198Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastembed-gpu\n",
      "  Downloading fastembed_gpu-0.6.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: qdrant-client[fastembed] in /usr/local/lib/python3.11/dist-packages (1.14.2)\n",
      "Collecting fastembed==0.6.1 (from qdrant-client[fastembed])\n",
      "  Downloading fastembed-0.6.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client[fastembed]) (1.70.0)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client[fastembed]) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from qdrant-client[fastembed]) (1.26.4)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client[fastembed]) (2.10.1)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client[fastembed]) (3.20.3)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from qdrant-client[fastembed]) (2.11.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant-client[fastembed]) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /usr/local/lib/python3.11/dist-packages (from fastembed==0.6.1->qdrant-client[fastembed]) (0.30.2)\n",
      "Collecting loguru<0.8.0,>=0.7.2 (from fastembed==0.6.1->qdrant-client[fastembed])\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting mmh3<6.0.0,>=4.1.0 (from fastembed==0.6.1->qdrant-client[fastembed])\n",
      "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting onnxruntime!=1.20.0,>=1.17.0 (from fastembed==0.6.1->qdrant-client[fastembed])\n",
      "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: pillow<12.0.0,>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from fastembed==0.6.1->qdrant-client[fastembed]) (11.1.0)\n",
      "Collecting py-rust-stemmers<0.2.0,>=0.1.0 (from fastembed==0.6.1->qdrant-client[fastembed])\n",
      "  Downloading py_rust_stemmers-0.1.5-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /usr/local/lib/python3.11/dist-packages (from fastembed==0.6.1->qdrant-client[fastembed]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from fastembed==0.6.1->qdrant-client[fastembed]) (0.21.0)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in /usr/local/lib/python3.11/dist-packages (from fastembed==0.6.1->qdrant-client[fastembed]) (4.67.1)\n",
      "Collecting onnxruntime-gpu!=1.20.0,>=1.17.0 (from fastembed-gpu)\n",
      "  Downloading onnxruntime_gpu-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client[fastembed]) (4.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed==0.6.1->qdrant-client[fastembed]) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed==0.6.1->qdrant-client[fastembed]) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed==0.6.1->qdrant-client[fastembed]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed==0.6.1->qdrant-client[fastembed]) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed==0.6.1->qdrant-client[fastembed]) (4.13.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client[fastembed]) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client[fastembed]) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client[fastembed]) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client[fastembed]) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client[fastembed]) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client[fastembed]) (2.4.1)\n",
      "Collecting coloredlogs (from onnxruntime-gpu!=1.20.0,>=1.17.0->fastembed-gpu)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu!=1.20.0,>=1.17.0->fastembed-gpu) (25.2.10)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu!=1.20.0,>=1.17.0->fastembed-gpu) (1.13.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client[fastembed]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client[fastembed]) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client[fastembed]) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed==0.6.1->qdrant-client[fastembed]) (3.4.1)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (4.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu!=1.20.0,>=1.17.0->fastembed-gpu)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->qdrant-client[fastembed]) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->qdrant-client[fastembed]) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21->qdrant-client[fastembed]) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21->qdrant-client[fastembed]) (2024.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu!=1.20.0,>=1.17.0->fastembed-gpu) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21->qdrant-client[fastembed]) (2024.2.0)\n",
      "Downloading fastembed-0.6.1-py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastembed_gpu-0.6.1-py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime_gpu-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.8/280.8 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading py_rust_stemmers-0.1.5-cp311-cp311-manylinux_2_28_x86_64.whl (324 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.8/324.8 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py-rust-stemmers, mmh3, loguru, humanfriendly, coloredlogs, onnxruntime, onnxruntime-gpu, fastembed, fastembed-gpu\n",
      "Successfully installed coloredlogs-15.0.1 fastembed-0.6.1 fastembed-gpu-0.6.1 humanfriendly-10.0 loguru-0.7.3 mmh3-5.1.0 onnxruntime-1.21.1 onnxruntime-gpu-1.21.1 py-rust-stemmers-0.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install \"qdrant-client[fastembed]\" fastembed-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-28T13:32:54.911130Z",
     "iopub.status.busy": "2025-04-28T13:32:54.910843Z",
     "iopub.status.idle": "2025-04-28T13:33:24.395807Z",
     "shell.execute_reply": "2025-04-28T13:33:24.395233Z",
     "shell.execute_reply.started": "2025-04-28T13:32:54.911101Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 13:33:10.694616: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745847190.905071      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745847190.968113      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import json\n",
    "import pandas as pd\n",
    "from qdrant_client import QdrantClient, AsyncQdrantClient, models\n",
    "from qdrant_client.http.models import Filter, FieldCondition, MatchValue\n",
    "# from qdrant_client.http import models\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import  StorageContext, load_index_from_storage, Settings, VectorStoreIndex, Document\n",
    "from llama_index.core.vector_stores import MetadataFilter, MetadataFilters, FilterOperator, FilterCondition\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "import cohere\n",
    "import asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:33:24.399181Z",
     "iopub.status.busy": "2025-04-28T13:33:24.398880Z",
     "iopub.status.idle": "2025-04-28T13:33:37.452684Z",
     "shell.execute_reply": "2025-04-28T13:33:37.452120Z",
     "shell.execute_reply.started": "2025-04-28T13:33:24.399163Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc63209f41754a7d8f63239dc09ed836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde79ce6b40043838bd018b628be804a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d04da6ae61d4c9ab4cb09c6facdf783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca294094ba34a5295a272f771c2dda6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe2cd68bf824c0fb8e1ac988489cafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caeafb75e6f04479a918558ac20600fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e30ccd59ba4473a843f326a1304885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16137e09f9a847dfac728aa840e2d078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f88d81c7d54c898e6fed4b1ea7536f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebe1caa94d04be28f0c4da45b776ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4618b82e096a426db53be9aa60508057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "embbeding_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "\n",
    "\n",
    "Settings.embed_model = embbeding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:33:37.453647Z",
     "iopub.status.busy": "2025-04-28T13:33:37.453380Z",
     "iopub.status.idle": "2025-04-28T13:33:37.919169Z",
     "shell.execute_reply": "2025-04-28T13:33:37.918631Z",
     "shell.execute_reply.started": "2025-04-28T13:33:37.453623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# client = AsyncQdrantClient(\n",
    "#     url= \"https://7690c3f5-dcaa-487f-a4f8-dc9740c23c22.europe-west3-0.gcp.cloud.qdrant.io\",\n",
    "#     api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.qZpquHIRvyNkuXv1n-6_D-tSE-U5rmzdmb8c8YebS4s\",\n",
    "# )\n",
    "\n",
    "client = QdrantClient(\n",
    "    url= \"\",\n",
    "    api_key=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:33:37.921612Z",
     "iopub.status.busy": "2025-04-28T13:33:37.921397Z",
     "iopub.status.idle": "2025-04-28T13:33:37.971409Z",
     "shell.execute_reply": "2025-04-28T13:33:37.970846Z",
     "shell.execute_reply.started": "2025-04-28T13:33:37.921571Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_level</th>\n",
       "      <th>salary</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>job_url</th>\n",
       "      <th>company_logo</th>\n",
       "      <th>company</th>\n",
       "      <th>company_industry</th>\n",
       "      <th>company_addresses</th>\n",
       "      <th>company_description</th>\n",
       "      <th>skills</th>\n",
       "      <th>description</th>\n",
       "      <th>qualifications &amp; skills</th>\n",
       "      <th>benefits</th>\n",
       "      <th>responsibilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in-ef57a978a800c1ea</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Thành phố Hồ Chí Minh, SG, VN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>Senior</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-19</td>\n",
       "      <td>https://vn.indeed.com/viewjob?jk=ef57a978a800c1ea</td>\n",
       "      <td>None</td>\n",
       "      <td>Zalo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>Hồ Chí Minh Full-time Senior Data Scientists i...</td>\n",
       "      <td>[3+ years of experience working in Big Data, M...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Advise business stakeholders on how to solve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in-acd80eabd538622c</td>\n",
       "      <td>Software Engineer, Java</td>\n",
       "      <td>Thành phố Hồ Chí Minh, SG, VN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-19</td>\n",
       "      <td>https://vn.indeed.com/viewjob?jk=acd80eabd538622c</td>\n",
       "      <td>None</td>\n",
       "      <td>Zalo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>Hồ Chí Minh Full-time Join the Core Features t...</td>\n",
       "      <td>[Proficiency in Java, Hands-on experience with...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Develop and maintain backend features for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in-235bf9d3e7892d76</td>\n",
       "      <td>Senior AI Engineer, Speech</td>\n",
       "      <td>Thành phố Hồ Chí Minh, SG, VN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-19</td>\n",
       "      <td>https://vn.indeed.com/viewjob?jk=235bf9d3e7892d76</td>\n",
       "      <td>None</td>\n",
       "      <td>Zalo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>Hồ Chí Minh Full-time Zalo AILab is looking fo...</td>\n",
       "      <td>[At least 3 years of experience building live ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Work closely with an active and talent team t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in-43171b35ddba17d7</td>\n",
       "      <td>Senior Software Engineer, Android</td>\n",
       "      <td>Thành phố Hồ Chí Minh, SG, VN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>Entry-Level</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-19</td>\n",
       "      <td>https://vn.indeed.com/viewjob?jk=43171b35ddba17d7</td>\n",
       "      <td>None</td>\n",
       "      <td>Zalo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>Hồ Chí Minh Full-time We are seeking an Androi...</td>\n",
       "      <td>[At least 3 years experiences experience with ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Develop video features: explore content, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in-a42cf0590c57d5b3</td>\n",
       "      <td>Software Engineer, Java</td>\n",
       "      <td>Thành phố Hồ Chí Minh, SG, VN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-19</td>\n",
       "      <td>https://vn.indeed.com/viewjob?jk=a42cf0590c57d5b3</td>\n",
       "      <td>None</td>\n",
       "      <td>Zalo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>Hồ Chí Minh Full-time As a core and feature ba...</td>\n",
       "      <td>[Minimum 2+ years of experience as a backend s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Participate in the design, development and im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                              title  \\\n",
       "0  in-ef57a978a800c1ea              Senior Data Scientist   \n",
       "1  in-acd80eabd538622c            Software Engineer, Java   \n",
       "2  in-235bf9d3e7892d76         Senior AI Engineer, Speech   \n",
       "3  in-43171b35ddba17d7  Senior Software Engineer, Android   \n",
       "4  in-a42cf0590c57d5b3            Software Engineer, Java   \n",
       "\n",
       "                        location  job_type    job_level salary  min_salary  \\\n",
       "0  Thành phố Hồ Chí Minh, SG, VN  fulltime       Senior                NaN   \n",
       "1  Thành phố Hồ Chí Minh, SG, VN  fulltime    Mid-Level                NaN   \n",
       "2  Thành phố Hồ Chí Minh, SG, VN  fulltime    Mid-Level                NaN   \n",
       "3  Thành phố Hồ Chí Minh, SG, VN  fulltime  Entry-Level                NaN   \n",
       "4  Thành phố Hồ Chí Minh, SG, VN  fulltime    Mid-Level                NaN   \n",
       "\n",
       "   max_salary date_posted                                            job_url  \\\n",
       "0         NaN  2025-04-19  https://vn.indeed.com/viewjob?jk=ef57a978a800c1ea   \n",
       "1         NaN  2025-04-19  https://vn.indeed.com/viewjob?jk=acd80eabd538622c   \n",
       "2         NaN  2025-04-19  https://vn.indeed.com/viewjob?jk=235bf9d3e7892d76   \n",
       "3         NaN  2025-04-19  https://vn.indeed.com/viewjob?jk=43171b35ddba17d7   \n",
       "4         NaN  2025-04-19  https://vn.indeed.com/viewjob?jk=a42cf0590c57d5b3   \n",
       "\n",
       "  company_logo company company_industry company_addresses company_description  \\\n",
       "0         None    Zalo             None              None                       \n",
       "1         None    Zalo             None              None                       \n",
       "2         None    Zalo             None              None                       \n",
       "3         None    Zalo             None              None                       \n",
       "4         None    Zalo             None              None                       \n",
       "\n",
       "  skills                                        description  \\\n",
       "0   None  Hồ Chí Minh Full-time Senior Data Scientists i...   \n",
       "1   None  Hồ Chí Minh Full-time Join the Core Features t...   \n",
       "2   None  Hồ Chí Minh Full-time Zalo AILab is looking fo...   \n",
       "3   None  Hồ Chí Minh Full-time We are seeking an Androi...   \n",
       "4   None  Hồ Chí Minh Full-time As a core and feature ba...   \n",
       "\n",
       "                             qualifications & skills benefits  \\\n",
       "0  [3+ years of experience working in Big Data, M...       []   \n",
       "1  [Proficiency in Java, Hands-on experience with...       []   \n",
       "2  [At least 3 years of experience building live ...       []   \n",
       "3  [At least 3 years experiences experience with ...       []   \n",
       "4  [Minimum 2+ years of experience as a backend s...       []   \n",
       "\n",
       "                                    responsibilities  \n",
       "0  [Advise business stakeholders on how to solve ...  \n",
       "1  [Develop and maintain backend features for the...  \n",
       "2  [Work closely with an active and talent team t...  \n",
       "3  [Develop video features: explore content, inte...  \n",
       "4  [Participate in the design, development and im...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r\"/kaggle/input/sample-grab-rag-data/linkedin_indeed.json\", \"rb\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:33:37.972390Z",
     "iopub.status.busy": "2025-04-28T13:33:37.972126Z",
     "iopub.status.idle": "2025-04-28T13:33:37.981931Z",
     "shell.execute_reply": "2025-04-28T13:33:37.981293Z",
     "shell.execute_reply.started": "2025-04-28T13:33:37.972362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def df_mapping(df):\n",
    "    # JOB_LEVEL MAPPING\n",
    "    level_mapping = {\n",
    "        \"senior\": \"Senior\",\n",
    "        \"mid level\": \"Mid-Level\",\n",
    "        \"mid senior level\": \"Mid-Level\",\n",
    "        \"entry level\": \"Entry-Level\",\n",
    "        \"not applicable\": \"Not Applicable\",\n",
    "        \"not specified\": \"Unspecified\",\n",
    "        \"unspecified\": \"Unspecified\",\n",
    "        \"director\": \"Director\",\n",
    "        \"internship\": \"Internship\",\n",
    "        \"manager\": \"Manager\",\n",
    "        \"professional\": \"Professional\",\n",
    "        \"junior\": \"Junior\",\n",
    "        \"executive\": \"Executive\",\n",
    "        \"associate\": \"Associate\"\n",
    "    }\n",
    "\n",
    "  \n",
    "    df[\"normalized_job_level\"] = (\n",
    "        df[\"job_level\"]\n",
    "        .str.lower()\n",
    "        .str.replace(\"-\", \" \", regex=False)\n",
    "        .str.strip()\n",
    "    )\n",
    "    df[\"mapped_level\"] = df[\"normalized_job_level\"].apply(lambda x: level_mapping.get(x, x))\n",
    "\n",
    "\n",
    "    location_mapping = {\n",
    "        \"thành phố hồ chí minh, sg, vn\": \"Ho Chi Minh City\",\n",
    "        \"hà nội, hn, vn\": \"Hanoi\",\n",
    "        \"57, vn\": \"Vietnam\",\n",
    "        \"vn\": \"Vietnam\",\n",
    "        \"đà nẵng, dn, vn\": \"Da Nang\",\n",
    "        \"hanoi, hanoi, vietnam\": \"Hanoi\",\n",
    "        \"ho chi minh city, ho chi minh city, vietnam\": \"Ho Chi Minh City\",\n",
    "        \"\": \"Unknown\",\n",
    "        \"ho chi minh city, vietnam\": \"Ho Chi Minh City\",\n",
    "        \"đình ba, hanoi, vietnam\": \"Hanoi\",\n",
    "        \"district 9, ho chi minh city, vietnam\": \"Ho Chi Minh City\"\n",
    "    }\n",
    "\n",
    "\n",
    "    df[\"normalized_location\"] = df[\"location\"].str.lower().str.strip()\n",
    "    df[\"mapped_location\"] = df[\"normalized_location\"].apply(lambda x: location_mapping.get(x, \"Other\"))\n",
    "\n",
    "\n",
    "    job_type_mapping = {\n",
    "        \"fulltime\": \"Full-Time\",\n",
    "        \"contract\": \"Contract\",\n",
    "        \"internship\": \"Internship\",\n",
    "        \"other\": \"Other\"\n",
    "    }\n",
    "    def map_job_type(job_type):\n",
    "        if isinstance(job_type, str):\n",
    "            job_type = job_type.lower().strip()\n",
    "            \n",
    " \n",
    "            if 'contract' in job_type:\n",
    "                return 'Contract'\n",
    "            elif 'internship' in job_type:\n",
    "                return 'Internship'\n",
    "            elif 'fulltime' in job_type:\n",
    "                return 'Full-Time'\n",
    "   \n",
    "            \n",
    "            \n",
    "\n",
    "            return job_type_mapping.get(job_type, \"Other\")\n",
    "        return \"Unknown\" \n",
    "\n",
    "\n",
    "    df[\"mapped_job_type\"] = df[\"job_type\"].apply(map_job_type)\n",
    "\n",
    "    return df\n",
    "\n",
    "def merging_data(df):\n",
    "    merged_texts = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        qs = \"\\n\".join(row[\"qualifications & skills\"]) if isinstance(row[\"qualifications & skills\"], list) else \"\"\n",
    "        responsibilities = \"\\n\".join(row[\"responsibilities\"]) if isinstance(row[\"responsibilities\"], list) else \"\"\n",
    "        \n",
    "        merge_text = rf\"\"\"\n",
    "Title: {row[\"title\"]}\n",
    "Job level: {row[\"job_level\"]}\n",
    "Working type: {row[\"job_type\"]}\n",
    "Company: {row[\"company\"]}\n",
    "Qualifications & Skills:\n",
    "{qs}\n",
    "\n",
    "Responsibilities:\n",
    "{responsibilities}\n",
    "\"\"\".strip()\n",
    "\n",
    "        merged_texts.append(merge_text)\n",
    "\n",
    "    return merged_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:33:37.982930Z",
     "iopub.status.busy": "2025-04-28T13:33:37.982653Z",
     "iopub.status.idle": "2025-04-28T13:33:38.006271Z",
     "shell.execute_reply": "2025-04-28T13:33:38.005718Z",
     "shell.execute_reply.started": "2025-04-28T13:33:37.982907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = df_mapping(df)\n",
    "merge_description = merging_data(df)\n",
    "df[\"merge_input\"] = merge_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:33:38.007456Z",
     "iopub.status.busy": "2025-04-28T13:33:38.007143Z",
     "iopub.status.idle": "2025-04-28T13:33:38.018622Z",
     "shell.execute_reply": "2025-04-28T13:33:38.018080Z",
     "shell.execute_reply.started": "2025-04-28T13:33:38.007439Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Senior Data Scientist\n",
      "Job level: Senior\n",
      "Working type: fulltime\n",
      "Company: Zalo\n",
      "Qualifications & Skills:\n",
      "3+ years of experience working in Big Data, Machine Learning, especially in recommendation areas, ideally in an industry-leading company\n",
      "BS, MS, Ph.D. in Statistics, Mathematics, Economics, Computer Science, or other quantitative fields\n",
      "Proficiency in programming using Python, Pytorch, SQL, NoSQL\n",
      "Proficiency in data structures and algorithms, machine learning, reinforcement learning, and deep learning\n",
      "Intellectual curiosity, effective communication, and excellent presentation skills\n",
      "Familiar with MLOps concept and toolkit is a plus\n",
      "Experience in the advertising area is a plus\n",
      "\n",
      "Responsibilities:\n",
      "Advise business stakeholders on how to solve problems with advanced analytics\n",
      "Build predictive models\n",
      "Work with engineers to deliver production model\n",
      "Research applied data science problems in our ads systems to improve prediction accuracy, auction strategies, and drive advertiser value\n",
      "Work closely with engineering and product teams to develop hypotheses, run experiments and prototype new product ideas\n",
      "Collaborate with data engineering teams to build/maintain reports, dashboards, and metrics to monitor the performance of our products, provide insights, and identify new opportunities.\n",
      "Apply technical expertise with quantitative analysis, experimentation, data mining, and the presentation of data to develop an understanding of the ads targeting/auction/delivery.\n"
     ]
    }
   ],
   "source": [
    "print(df[\"merge_input\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:05:52.735975Z",
     "iopub.status.busy": "2025-04-28T13:05:52.735302Z",
     "iopub.status.idle": "2025-04-28T13:05:53.140873Z",
     "shell.execute_reply": "2025-04-28T13:05:53.140225Z",
     "shell.execute_reply.started": "2025-04-28T13:05:52.735952Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_collection(collection_name=\"job_description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:34:46.049568Z",
     "iopub.status.busy": "2025-04-28T13:34:46.049266Z",
     "iopub.status.idle": "2025-04-28T13:34:46.053873Z",
     "shell.execute_reply": "2025-04-28T13:34:46.053166Z",
     "shell.execute_reply.started": "2025-04-28T13:34:46.049547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dense_vector_name = \"text-dense\"\n",
    "sparse_vector_name = \"text-sparse\"\n",
    "dense_model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "sparse_model_name = \"prithivida/Splade_PP_en_v1\"\n",
    "if not client.collection_exists(\"job_description\"):\n",
    "    client.create_collection(\n",
    "        collection_name=\"job_description\",\n",
    "        vectors_config={\n",
    "            dense_vector_name: models.VectorParams(\n",
    "                size=client.get_embedding_size(dense_model_name), \n",
    "                distance=models.Distance.COSINE\n",
    "            )\n",
    "        },  \n",
    "        sparse_vectors_config={sparse_vector_name: models.SparseVectorParams()},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:05:53.580610Z",
     "iopub.status.busy": "2025-04-28T13:05:53.580304Z",
     "iopub.status.idle": "2025-04-28T13:05:53.592560Z",
     "shell.execute_reply": "2025-04-28T13:05:53.591978Z",
     "shell.execute_reply.started": "2025-04-28T13:05:53.580593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "metadata = []\n",
    "for index, row in df.iterrows():\n",
    "    meta = {\n",
    "        \"id\": row[\"id\"],\n",
    "        \"level\": row[\"mapped_level\"],\n",
    "        \"title\": row[\"title\"],\n",
    "        \"company\": row[\"company\"],\n",
    "        \"link\": row[\"job_url\"],\n",
    "        \"job_type\": row[\"mapped_job_type\"],\n",
    "        \"location\": row[\"mapped_location\"],\n",
    "        \"text\":row[\"merge_input\"],\n",
    "        # \"keyword\": row[\"search_keyword\"],\n",
    "    }\n",
    "    dense_document = models.Document(text=row[\"merge_input\"], model=dense_model_name)\n",
    "    sparse_document = models.Document(text=row[\"merge_input\"], model=sparse_model_name)\n",
    "    documents.append({\n",
    "        dense_vector_name: dense_document,\n",
    "        sparse_vector_name: sparse_document,\n",
    "    })\n",
    "    metadata.append(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:05:53.593479Z",
     "iopub.status.busy": "2025-04-28T13:05:53.593262Z",
     "iopub.status.idle": "2025-04-28T13:08:18.951937Z",
     "shell.execute_reply": "2025-04-28T13:08:18.950964Z",
     "shell.execute_reply.started": "2025-04-28T13:05:53.593452Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:05<00:00,  1.12s/it]\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:05<00:00,  1.09s/it]\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:02<00:00,  2.14it/s]\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:02<00:00,  2.43it/s]\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:02<00:00,  2.19it/s]\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:01<00:00,  4.85it/s]\n",
      "100%|██████████| 96/96 [01:47<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "client.upload_collection(\n",
    "        collection_name=\"job_description\",\n",
    "        vectors=documents,\n",
    "        payload=metadata,\n",
    "        parallel=4,\n",
    "        ids=tqdm(range(len(documents)))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:34:52.433557Z",
     "iopub.status.busy": "2025-04-28T13:34:52.433280Z",
     "iopub.status.idle": "2025-04-28T13:34:52.442215Z",
     "shell.execute_reply": "2025-04-28T13:34:52.441167Z",
     "shell.execute_reply.started": "2025-04-28T13:34:52.433535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HybridRetriever:\n",
    "    DENSE_MODEL = \"BAAI/bge-large-en-v1.5\"\n",
    "    SPARSE_MODEL = \"prithivida/Splade_PP_en_v1\"\n",
    "    \n",
    "    def __init__(self, collection_name, client):\n",
    "        self.collection_name = collection_name\n",
    "        self.qdrant_client = client\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_metadata_filter(fields: dict):\n",
    "        \"\"\"Helper to build metadata filters compatible with Qdrant.\"\"\"\n",
    "        if not fields:\n",
    "            return None\n",
    "        \n",
    "        conditions = [\n",
    "            FieldCondition(\n",
    "                key=key,\n",
    "                match=MatchValue(value=value)\n",
    "            )\n",
    "            for key, value in fields.items()\n",
    "        ]\n",
    "        return Filter(must=conditions)\n",
    "\n",
    "    def search(self, text: str, metadata_filter: dict = None, top_k: int = 5):\n",
    "        \"\"\"Perform hybrid (dense + sparse) search with optional metadata filtering.\"\"\"\n",
    "        \n",
    "        query_filter = self._build_metadata_filter(metadata_filter)\n",
    "\n",
    "        search_result = self.qdrant_client.query_points(\n",
    "            collection_name=self.collection_name,\n",
    "            query=models.FusionQuery(\n",
    "                fusion=models.Fusion.RRF\n",
    "            ),\n",
    "            prefetch=[\n",
    "                models.Prefetch(\n",
    "                    query=models.Document(text=text, model=self.DENSE_MODEL),\n",
    "                    using = dense_vector_name,\n",
    "                    limit = top_k\n",
    "                ),\n",
    "                models.Prefetch(\n",
    "                    query=models.Document(text=text, model=self.SPARSE_MODEL),\n",
    "                    using = sparse_vector_name,\n",
    "                    limit = top_k\n",
    "                ),\n",
    "            ],\n",
    "            query_filter=query_filter,\n",
    "            with_payload=True,\n",
    "            with_vectors=False,\n",
    "            limit=top_k,\n",
    "        ).points\n",
    "\n",
    "        enriched = []\n",
    "        for pt in search_result:\n",
    "            payload = pt.payload or {}\n",
    "            enriched.append({\n",
    "                \"id\": pt.id,\n",
    "                \"score\": pt.score,\n",
    "                \"text\": payload.get(\"text\"),   \n",
    "                **{k: v for k, v in payload.items() if k != \"text\"}  \n",
    "            })\n",
    "        return enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:34:52.636373Z",
     "iopub.status.busy": "2025-04-28T13:34:52.635750Z",
     "iopub.status.idle": "2025-04-28T13:34:52.642329Z",
     "shell.execute_reply": "2025-04-28T13:34:52.641622Z",
     "shell.execute_reply.started": "2025-04-28T13:34:52.636353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "LE DUC TAI\n",
    "Phone:\n",
    "Linkedin:\n",
    "Email: \n",
    "Github: \n",
    "ORCID:\n",
    "Google Scholar:\n",
    "SUMMARY\n",
    "\n",
    "0783349553\n",
    "Duc Tai Le\n",
    "leductai2201@gmail.com\n",
    "NBTailee\n",
    "Duc Tai Le\n",
    "Le Duc Tai\n",
    "\n",
    "As an AI Engineer intern specializing in Large Language Models (LLMs), I want to gain hands-on experience fine-\n",
    "tuning  and  optimizing  NLP,  Generative  AI  models  and  RAG  for  specific  applications.  I  worked  on  building  web\n",
    "applications,  model  finetuning.  Additionally,  I  also  want  to  explored  cutting-edge  techniques  like  prompt\n",
    "engineering and transfer learning. I have some experience with HuggingFace, YOLO, Pytorch, Flask, NodeJS and\n",
    "ReactJS.\n",
    "\n",
    "EDUCATION\n",
    "\n",
    "Currently Studying Bachelor of Computer Science\n",
    "University of Information Technology of Ho Chi Minh city (UIT)\n",
    "\n",
    "Machine Learning team member of AI club of UIT.\n",
    "\n",
    "LANGUAGES\n",
    "\n",
    "IELTS: 6.5 overall\n",
    "\n",
    "RESEARCH PAPERS & PUBLICATIONS\n",
    "\n",
    "GPA: 3.5\n",
    "\n",
    "MMLabUIT at CoMeDi Shared Task: Text Embedding Techniques versus Generation-Based NLI for\n",
    "Median Judgment Classification.\n",
    "\n",
    "      Conference: COLING ranking A\n",
    "\n",
    "Classification of racial stereotypes in Spanish With Ensemble Learning Methods and BERT-based\n",
    "Adapter Head.\n",
    "      Conference: IberLEF\n",
    "\n",
    " AWARDS & CERTIFICATIONS\n",
    "\n",
    "Top 3rd CoMeDi competition track 1 of COLING 2025 conference\n",
    "Top 8th in SemEval 2025 track 9 The Food Hazard Detection Challenge of ACL conference.\n",
    "Top 9th  DETEST-Dis IberLef 2024 competition track 1 of SEPLN conference\n",
    "Top 34th in AI City Challenge 2024 competition Track 5\n",
    "Data Scientist Associate Certificate - Datacamp\n",
    "IBM Data Science Specialization - IBM\n",
    "Machine Learning Specialization - DeepLearning.io\n",
    "SQL (Intermediate) Certificate - Hackerrank\n",
    "\n",
    "SKILLS & TECH STACK\n",
    "\n",
    "AI/ML: Pytorch, Tensorflow, scikit-learn, pandas, numpy, matplotlib.\n",
    "NLP/LLM & RAG/Agent: HuggingFace, LLamaIndex, LangChains, NLTK, Gemini LLM, CohereAI.\n",
    "\n",
    "Developing multi-query system with different techniques to enhance retrieved content quality.\n",
    "Can apply Prompt engineering in AI solution with prompt format, prompt techniques.\n",
    "Conducting new NLP approaches for many problem in real world.\n",
    "Use different LLM in one system with flexible purpose.\n",
    "Computer Vision: YOLO(Ultralytics), EasyOCR, Roboflow.\n",
    "\n",
    "Developing high accuracy and inference speed detection, OCR real-time system.\n",
    "\n",
    "Back-End: Flask, NodeJS, Postman.\n",
    "\n",
    "have pretty solid knowledge in CRUD app and intermediate in RESTapi.\n",
    "Can create end-to-end project integrated with AI/ML solutions.\n",
    "\n",
    "Front-End: ReactJS, Redux, Streamlit, Gradio, MaterialUI.\n",
    "\n",
    "have solid skill in developing web UI based on requirements.\n",
    "\n",
    "Database: MongoDB, PinconeDB, ChromaDB, MySQL.\n",
    "Research skills: Google Scholar, ACL anathology.\n",
    "\n",
    "Have more than 1 years experience in researching about NLP/LLM topics and also have research\n",
    "papers.\n",
    "\n",
    "\fPROJECTS\n",
    "\n",
    "UIT Agent with multi flow answering system\n",
    "\n",
    "Small Talk Detection: Implements a system to distinguish casual conversation queries and route them\n",
    "appropriately.\n",
    "Dynamic Query Transformation: Utilizes HyDE Query Transformation to enhance search performance for\n",
    "complex queries.\n",
    "Hybrid Search Integration: Combines BM25 and Semantic Search for precise and contextually relevant\n",
    "results.\n",
    "Metadata Filtering and Retrieval: Ensures accurate historical context retrieval through metadata filtering.\n",
    "Query Re-ranking: Optimizes search result order based on relevance and context using reranking\n",
    "mechanisms.\n",
    "HuggingFace LLM Integration: Leverages HuggingFace for advanced natural language understanding and\n",
    "response generation.\n",
    "Scalable Architecture: Multi-stage query pipeline with modular end-to-end resolution.\n",
    "Tech Stack: Pinecone, LlamaIndex, Hugging Face, Gemini, Cohere, Flask, ReactJS.\n",
    "\n",
    "AI information retrieval Web Application\n",
    "\n",
    "Text Processing: Extracted token length, conducted sentiment analysis, emotion classification, and\n",
    "summarized text in English and Vietnamese. Fine-tuned \"phoBART-syllable-base\" for superior Vietnamese\n",
    "text summarization with QLora and Quantization techniques.\n",
    "Image Analysis: Implemented object detection, optical character recognition (OCR), and image captioning\n",
    "using zero-shot learning models from Ultralytics and EasyOCR.\n",
    "Audio Recognition: Developed capabilities for audio-to-text conversion and sound classification.\n",
    "\n",
    "RAG chatbot for course information\n",
    "\n",
    "Designed and implemented a Retrieval-Augmented Generation (RAG) application utilizing the Vietstral-7B\n",
    "model from HuggingFace.\n",
    "Integrated advanced LangChains and CohereAI capabilities to enhance model performance.\n",
    "Utilized ChromaDB as the retrieval database, employing Cosine similarity and Reranker techniques for\n",
    "efficient and accurate data retrieval from large datasets.\n",
    "Enabled context-aware responses by feeding retrieved data into the LLM.\n",
    "Developed an intuitive user interface for the application using Gradio.\n",
    "\n",
    "Median Judgment Classification in 7 Languages\n",
    "\n",
    "Advanced NLP Techniques: Implemented stacked embeddings, averaged embeddings, and Natural\n",
    "Language Inference (NLI) with BERT-based and generative models.\n",
    "Custom Token & Data Processing: Enhanced model performance through custom tokens, data\n",
    "augmentation, and Named Entity Recognition (NER)-based preprocessing.\n",
    "Evaluation & Optimization: Achieved 0.596 Krippendorff’s α score, significantly improving baseline\n",
    "classification results.\n",
    "Machine Learning & NLP: BERT, RoBERTa, XLM-R, BART, Cosine Similarity, NLI\n",
    "Data Processing: Stratified K-Fold Cross-Validation, Lemmatization, Text Expansion\n",
    "Development Frameworks: Hugging Face, PyTorch, TensorFlow\n",
    "Computational Resources: Fine-tuned models on Kaggle P100 GPUs using AdamW & AdaFactor optimizers\n",
    "\n",
    "Stereotype classification in Spanish\n",
    "\n",
    "Finetuning BETO, RoBERTa, XLM-RoBERTa, mDeBERTa-v3, DeHATEbert.\n",
    "Finetuning XLM-RoBERTa-twitter-hate.\n",
    "Using ensemble learning methods: Hard-voting, Soft-voting, Stacking.\n",
    "Make use of Adapter Head to improve performance.\n",
    " Apply Handcraft-Features for BERT-based models.\n",
    " Finetuning SVM, RandomForest with GridSearchCV, cross-validation.\n",
    "\n",
    "Detecting Violation of Helmet Rule for Motorcyclists\n",
    "\n",
    "Helmet Rule Violation Detection: Developed an AI-powered system to detect motorcyclist helmet\n",
    "violations using state-of-the-art object detection models.\n",
    "Addressed Key Challenges: Tackled unbalanced data and small object detection issues by fine-tuning\n",
    "YOLOv8 with a p2 head and implementing the SAHI algorithm to enhance precision and recall.\n",
    "Advanced Object Detection Models: Fine-tuned Real-Time DETR for accurate object detection and\n",
    "integrated the latest YOLOv9 for improved efficiency.\n",
    "Deep Learning & Computer Vision: YOLOv8, YOLOv9, DETR, SAHI algorithm\n",
    "Model Optimization: Fine-tuning, small object detection enhancement, precision-recall improvement\n",
    "Development Frameworks: PyTorch, TensorFlow, OpenCV\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:43:00.889720Z",
     "iopub.status.busy": "2025-04-28T13:43:00.889389Z",
     "iopub.status.idle": "2025-04-28T13:43:03.803052Z",
     "shell.execute_reply": "2025-04-28T13:43:03.802410Z",
     "shell.execute_reply.started": "2025-04-28T13:43:00.889700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "retriever = HybridRetriever(collection_name = \"job_description\", client = client)\n",
    "results = retriever.search(text = query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:43:03.804328Z",
     "iopub.status.busy": "2025-04-28T13:43:03.804099Z",
     "iopub.status.idle": "2025-04-28T13:43:03.808639Z",
     "shell.execute_reply": "2025-04-28T13:43:03.808042Z",
     "shell.execute_reply.started": "2025-04-28T13:43:03.804306Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "Title: Software Engineer C/C++ AI\n",
      "Job level: entry level\n",
      "Working type: fulltime\n",
      "Company: Viettel High Tech\n",
      "Qualifications & Skills:\n",
      "Đại học tốt nghiệp loại Khá hoặc Thạc sĩ, Tiến sĩ chuyên ngành CNTT/Khoa học máy tính/Toán tin/Điện tử Viễn thông hoặc các chuyên ngành liên quan khác\n",
      "Yêu cầu 1 năm kinh nghiệm lập trình C/C++\n",
      "Trình độ Tiếng Anh tương đương tối thiểu 550 điểm Toeic\n",
      "Ưu tiên Cấp 3 học chuyên Toán, Tin, Lý, Hóa có giải thành phố, quốc gia, quốc tế\n",
      "Có ý chí và mong muốn mãnh liệt để thành chuyên gia cao cấp\n",
      "Nghiên cứu sâu, đam mê lập trình, làm chủ công nghệ lõi, áp dụng hàng triệu triệu thiết bị, nền tảng trăm triệu người dùng, chất lượng top thế giới\n",
      "Chính trực, siêng năng, nhiệt huyết, chủ động nghiên cứu, học tập, nâng cao kĩ năng kiến thức\n",
      "\n",
      "Responsibilities:\n",
      "Triển khai lập trình MLOps cho các mô hình AI biên\n",
      "Triển khai lập trình ứng dụng lớp Firmware bằng C/C++\n",
      "Nghiên cứu thế giới, thiết kế các giao thức truyền tải trong mạng IP sâu đến tầng TCP, UDP với các kĩ thuật kiểm soát packet loss, delay, jitter..\n",
      "Phát triển các chương trình khung, viết các yêu cầu thiết kế chặt chẽ, đảm bảo tuân thủ các nguyên tắc lập trình chuẩn mực, chặt chẽ, tối ưu hiệu năng, mở rộng không giới hạn\n",
      "Được tham gia phát triển giao thức network, streaming, tranmission, p2p, cloud recording.. bằng C/C++ nhúng vào Device thiết bị , App Mobile, Backend\n",
      "Được nghiên cứu và thực hiện tích hợp code C/C++ vào JNI Mobile App iOS/Android/Flutter/React\n",
      "Được nghiên cứu và thực hiện tích hợp code C/C++ vào Java/Golang\n",
      "Được nghiên cứu và thực hiện về giao thức mạng, chuẩn Media như TCP, UDP, STUN, Video, Audio, Streaming, Framing, ARG, FEC\n",
      "Được nghiên cứu và thực hiện các phương pháp tối ưu giao thức, chống lỗi, nghẽn đảm bảo chất lượng truyền tải\n",
      "Tham gia vào việc phân tích, thiết kế, và thực thi các chuẩn giao thức\n",
      "Nghiên cứu các công nghệ mới về giao thức và áp dụng thực tế\n",
      "Nghiên cứu các patent, bài báo, được tài trợ viết bài báo, sáng chế.. đăng kí quốc gia quốc tế\n",
      "0.5\n",
      "Title: Software Engineer Intern\n",
      "Job level: internship\n",
      "Working type: fulltime\n",
      "Company: Rakuna\n",
      "Qualifications & Skills:\n",
      "Commit at least 6-months as full-time intern may have the opportunity to be offered full-time position post-internship if shown excellency at work.\n",
      "Currently enrolled in a Bachelor s program in Computer Science, Information Technology or a related technical field.\n",
      "Experience of coding in one of the following programming languages including but not limited to: Ruby, C++, Java, Python, Go.....\n",
      "Demonstrated interest and ability to learn other coding languages as needed.\n",
      "Developed communication skills, and adequate ability to speak and write in English.\n",
      "Effective teamwork, project management, creative problem-solving.\n",
      "strong communication skills.\n",
      "Technology internship experience or work experience e.g: research assistant, teaching assistant, personal projects, etc.\n",
      "Interested in or love the startup-like environment, want to challenge self and aim for a leadership prospect.\n",
      "\n",
      "Responsibilities:\n",
      "Assist in building and/or managingproduct pipelines including planning, development, and maintenance.\n",
      "Analyze information and evaluate results to choose the best solution to effectively solve problems.\n",
      "Provide quality assurance QA support through product testings.\n",
      "Work with peers, managers, and teams to create and support core functional teams - Sales Marketing, Quality and Customer Success, and Operations.\n",
      "Learn in-depth about how to create a product in a start-up environment.\n",
      "0.4166667\n",
      "Title: Software Engineer Intern\n",
      "Job level: Internship\n",
      "Working type: internship\n",
      "Company: Homebase (YC W'21)\n",
      "Qualifications & Skills:\n",
      "Based in Ho Chi Minh City\n",
      "Majoring in Computer Science, IT, Engineering, or related fields in a top tier university\n",
      "Be able to commit at least 6 months\n",
      "Experienced in Python\n",
      "Familiarity with database systems and data modeling is a plus\n",
      "Prior internship experience in Engineering is a plus\n",
      "Strong passion for growth hacking, infrastructure and data scraping\n",
      "Strong communication and collaboration skills to work effectively in a team environment\n",
      "Self-driven, proactive, and comfortable working in a fast-paced, dynamic startup culture\n",
      "\n",
      "Responsibilities:\n",
      "Collaborate with Backend Engineer to assist in the design, deployment, and maintenance of robust and scalable infrastructure\n",
      "Assist in the engineering tasks, including ingestion, transformation, and integration\n",
      "Design, develop, and maintain data pipelines and ETL processes for extracting, transforming, and loading data from diverse sources into our data warehouses and systems\n",
      "Develop and maintain data scraping scripts/tools for gathering information from online sources\n",
      "Optimize database performance by monitoring, making necessary changes, and applying updates\n",
      "Implement data security and privacy best practices, ensuring compliance with relevant data protection regulations\n",
      "Build high-quality, highly available database systems tailored to end users roles\n",
      "Implement high-speed transaction recovery techniques and data backup\n",
      "Identify opportunities for user acquisition and engagement\n",
      "0.36666667\n",
      "Title: Senior AI Engineer, Speech\n",
      "Job level: Mid-Level\n",
      "Working type: fulltime\n",
      "Company: Zalo\n",
      "Qualifications & Skills:\n",
      "At least 3 years of experience building live speech recognition, speech synthesis, or speech enhancement products\n",
      "Have the ability to mentor members\n",
      "Passionate about working with speech challenges\n",
      "Master deep learning frameworks PyTorch, TensorFlow\n",
      "Experience with TensorRT and TensorFlow Lite is a plus\n",
      "Strong programming skill in Python, C++ or Java\n",
      "Strong communication skills and a strong growth mindset\n",
      "\n",
      "Responsibilities:\n",
      "Work closely with an active and talent team to research and propose efficient architectures for speech processing challenges\n",
      "Build high-performance and high-quality speech synthesizer, enhancement and recognition models\n",
      "Be responsible for data analysis, training, evaluation and related deployment systems\n",
      "Utilize machine learning technologies for speech processing\n",
      "Non-stop looking for new state-of-the-art approaches and open-mind to the differences\n",
      "Stay on time and deliver exceptional products\n",
      "0.33333334\n",
      "Title: Senior Data Scientist - Open to Relocation\n",
      "Job level: mid-senior level\n",
      "Working type: fulltime\n",
      "Company: MTI Technology\n",
      "Qualifications & Skills:\n",
      "Be fluent in English.\n",
      "Have a bachelor s degree in Computer Science, Applied Mathematics, or related fields.\n",
      "Have at least 5 years of industrial experience in NLP and/or Machine Learning tabular data .\n",
      "Expert in Python with production-ready code.\n",
      "Advanced skills in GitHub/GitLab, SQL, and data visualization.\n",
      "Proven ML expertise ensemble methods, deep learning using TensorFlow/PyTorch.\n",
      "Mastery of tabular data XGBoost, PCA and NLP transformers, sequence modeling .\n",
      "Skilled in training/serving custom LLMs GPT with TensorFlow Serving, FastAPI, Docker/Kubernetes.\n",
      "Expert in GCP BigQuery, Vertex AI for scalable model deployment/monitoring.\n",
      "Proficient in using ChatGPT/Gemini for advanced applications e.g., conversational AI with prompt optimization.\n",
      "Experienced in MLOps and solution design.\n",
      "Capable of researching, reading publications, and translating research papers into code.\n",
      "Have excellent problem-solving skills.\n",
      "Be self-motivated and eager to learn new technologies and techniques.\n",
      "Be good at communication and presentation: able to communicate with non-tech stakeholders to understand business as well as present technical solutions.\n",
      "Have experience in leading data science team.\n",
      "Experience in Big Data, cloud AWS, Google Cloud, Azure .\n",
      "Familiar with working with Agile process.\n",
      "A deep understanding of a specific domain or industry vertical insurance, logistics\n",
      "\n",
      "Responsibilities:\n",
      "Participate in the entire lifecycle of data science projects, from problem definition to solution delivery, and maintenance.\n",
      "Develop, test, and evaluate data hypotheses, methods, and models using appropriate techniques and tools.\n",
      "Collaborate with engineers to implement scalable and robust data pipelines and systems.\n",
      "Stay updated on the latest research and trends in data science.\n",
      "Analyze client data and business needs to identify opportunities and propose data-driven solutions.\n",
      "Communicate and present your findings and recommendations to clients and stakeholders clearly and effectively.\n",
      "Lead data science projects as well as provide guidance/mentorship to junior, middle data scientists.\n",
      "Manage multiple projects.\n"
     ]
    }
   ],
   "source": [
    "for d in results:\n",
    "    print(d[\"score\"])\n",
    "    print(d[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:43:12.412744Z",
     "iopub.status.busy": "2025-04-28T13:43:12.412351Z",
     "iopub.status.idle": "2025-04-28T13:43:12.783395Z",
     "shell.execute_reply": "2025-04-28T13:43:12.782838Z",
     "shell.execute_reply.started": "2025-04-28T13:43:12.412724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "co = cohere.Client(\"\")\n",
    "\n",
    "document_list = [point['text'] for point in results]\n",
    "rerank_results = co.rerank(\n",
    "    model=\"rerank-english-v3.0\",\n",
    "    query=query,\n",
    "    documents=document_list,\n",
    "    top_n=5,\n",
    ")\n",
    "# for d in rerank_results:\n",
    "#     print(d[\"score\"])\n",
    "#     print(d[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T13:43:16.052195Z",
     "iopub.status.busy": "2025-04-28T13:43:16.051454Z",
     "iopub.status.idle": "2025-04-28T13:43:16.057058Z",
     "shell.execute_reply": "2025-04-28T13:43:16.056279Z",
     "shell.execute_reply.started": "2025-04-28T13:43:16.052172Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank #1\n",
      "Score: 0.6264\n",
      "Document: Title: Software Engineer Intern\n",
      "Job level: Internship\n",
      "Working type: internship\n",
      "Company: Homebase (YC W'21)\n",
      "Qualifications & Skills:\n",
      "Based in Ho Chi Minh City\n",
      "Majoring in Computer Science, IT, Engineering, or related fields in a top tier university\n",
      "Be able to commit at least 6 months\n",
      "Experienced in Python\n",
      "Familiarity with database systems and data modeling is a plus\n",
      "Prior internship experience in Engineering is a plus\n",
      "Strong passion for growth hacking, infrastructure and data scraping\n",
      "Strong communication and collaboration skills to work effectively in a team environment\n",
      "Self-driven, proactive, and comfortable working in a fast-paced, dynamic startup culture\n",
      "\n",
      "Responsibilities:\n",
      "Collaborate with Backend Engineer to assist in the design, deployment, and maintenance of robust and scalable infrastructure\n",
      "Assist in the engineering tasks, including ingestion, transformation, and integration\n",
      "Design, develop, and maintain data pipelines and ETL processes for extracting, transforming, and loading data from diverse sources into our data warehouses and systems\n",
      "Develop and maintain data scraping scripts/tools for gathering information from online sources\n",
      "Optimize database performance by monitoring, making necessary changes, and applying updates\n",
      "Implement data security and privacy best practices, ensuring compliance with relevant data protection regulations\n",
      "Build high-quality, highly available database systems tailored to end users roles\n",
      "Implement high-speed transaction recovery techniques and data backup\n",
      "Identify opportunities for user acquisition and engagement\n",
      "==================================================\n",
      "Rank #2\n",
      "Score: 0.3872\n",
      "Document: Title: Software Engineer C/C++ AI\n",
      "Job level: entry level\n",
      "Working type: fulltime\n",
      "Company: Viettel High Tech\n",
      "Qualifications & Skills:\n",
      "Đại học tốt nghiệp loại Khá hoặc Thạc sĩ, Tiến sĩ chuyên ngành CNTT/Khoa học máy tính/Toán tin/Điện tử Viễn thông hoặc các chuyên ngành liên quan khác\n",
      "Yêu cầu 1 năm kinh nghiệm lập trình C/C++\n",
      "Trình độ Tiếng Anh tương đương tối thiểu 550 điểm Toeic\n",
      "Ưu tiên Cấp 3 học chuyên Toán, Tin, Lý, Hóa có giải thành phố, quốc gia, quốc tế\n",
      "Có ý chí và mong muốn mãnh liệt để thành chuyên gia cao cấp\n",
      "Nghiên cứu sâu, đam mê lập trình, làm chủ công nghệ lõi, áp dụng hàng triệu triệu thiết bị, nền tảng trăm triệu người dùng, chất lượng top thế giới\n",
      "Chính trực, siêng năng, nhiệt huyết, chủ động nghiên cứu, học tập, nâng cao kĩ năng kiến thức\n",
      "\n",
      "Responsibilities:\n",
      "Triển khai lập trình MLOps cho các mô hình AI biên\n",
      "Triển khai lập trình ứng dụng lớp Firmware bằng C/C++\n",
      "Nghiên cứu thế giới, thiết kế các giao thức truyền tải trong mạng IP sâu đến tầng TCP, UDP với các kĩ thuật kiểm soát packet loss, delay, jitter..\n",
      "Phát triển các chương trình khung, viết các yêu cầu thiết kế chặt chẽ, đảm bảo tuân thủ các nguyên tắc lập trình chuẩn mực, chặt chẽ, tối ưu hiệu năng, mở rộng không giới hạn\n",
      "Được tham gia phát triển giao thức network, streaming, tranmission, p2p, cloud recording.. bằng C/C++ nhúng vào Device thiết bị , App Mobile, Backend\n",
      "Được nghiên cứu và thực hiện tích hợp code C/C++ vào JNI Mobile App iOS/Android/Flutter/React\n",
      "Được nghiên cứu và thực hiện tích hợp code C/C++ vào Java/Golang\n",
      "Được nghiên cứu và thực hiện về giao thức mạng, chuẩn Media như TCP, UDP, STUN, Video, Audio, Streaming, Framing, ARG, FEC\n",
      "Được nghiên cứu và thực hiện các phương pháp tối ưu giao thức, chống lỗi, nghẽn đảm bảo chất lượng truyền tải\n",
      "Tham gia vào việc phân tích, thiết kế, và thực thi các chuẩn giao thức\n",
      "Nghiên cứu các công nghệ mới về giao thức và áp dụng thực tế\n",
      "Nghiên cứu các patent, bài báo, được tài trợ viết bài báo, sáng chế.. đăng kí quốc gia quốc tế\n",
      "==================================================\n",
      "Rank #3\n",
      "Score: 0.3173\n",
      "Document: Title: Senior Data Scientist - Open to Relocation\n",
      "Job level: mid-senior level\n",
      "Working type: fulltime\n",
      "Company: MTI Technology\n",
      "Qualifications & Skills:\n",
      "Be fluent in English.\n",
      "Have a bachelor s degree in Computer Science, Applied Mathematics, or related fields.\n",
      "Have at least 5 years of industrial experience in NLP and/or Machine Learning tabular data .\n",
      "Expert in Python with production-ready code.\n",
      "Advanced skills in GitHub/GitLab, SQL, and data visualization.\n",
      "Proven ML expertise ensemble methods, deep learning using TensorFlow/PyTorch.\n",
      "Mastery of tabular data XGBoost, PCA and NLP transformers, sequence modeling .\n",
      "Skilled in training/serving custom LLMs GPT with TensorFlow Serving, FastAPI, Docker/Kubernetes.\n",
      "Expert in GCP BigQuery, Vertex AI for scalable model deployment/monitoring.\n",
      "Proficient in using ChatGPT/Gemini for advanced applications e.g., conversational AI with prompt optimization.\n",
      "Experienced in MLOps and solution design.\n",
      "Capable of researching, reading publications, and translating research papers into code.\n",
      "Have excellent problem-solving skills.\n",
      "Be self-motivated and eager to learn new technologies and techniques.\n",
      "Be good at communication and presentation: able to communicate with non-tech stakeholders to understand business as well as present technical solutions.\n",
      "Have experience in leading data science team.\n",
      "Experience in Big Data, cloud AWS, Google Cloud, Azure .\n",
      "Familiar with working with Agile process.\n",
      "A deep understanding of a specific domain or industry vertical insurance, logistics\n",
      "\n",
      "Responsibilities:\n",
      "Participate in the entire lifecycle of data science projects, from problem definition to solution delivery, and maintenance.\n",
      "Develop, test, and evaluate data hypotheses, methods, and models using appropriate techniques and tools.\n",
      "Collaborate with engineers to implement scalable and robust data pipelines and systems.\n",
      "Stay updated on the latest research and trends in data science.\n",
      "Analyze client data and business needs to identify opportunities and propose data-driven solutions.\n",
      "Communicate and present your findings and recommendations to clients and stakeholders clearly and effectively.\n",
      "Lead data science projects as well as provide guidance/mentorship to junior, middle data scientists.\n",
      "Manage multiple projects.\n",
      "==================================================\n",
      "Rank #4\n",
      "Score: 0.2242\n",
      "Document: Title: Senior AI Engineer, Speech\n",
      "Job level: Mid-Level\n",
      "Working type: fulltime\n",
      "Company: Zalo\n",
      "Qualifications & Skills:\n",
      "At least 3 years of experience building live speech recognition, speech synthesis, or speech enhancement products\n",
      "Have the ability to mentor members\n",
      "Passionate about working with speech challenges\n",
      "Master deep learning frameworks PyTorch, TensorFlow\n",
      "Experience with TensorRT and TensorFlow Lite is a plus\n",
      "Strong programming skill in Python, C++ or Java\n",
      "Strong communication skills and a strong growth mindset\n",
      "\n",
      "Responsibilities:\n",
      "Work closely with an active and talent team to research and propose efficient architectures for speech processing challenges\n",
      "Build high-performance and high-quality speech synthesizer, enhancement and recognition models\n",
      "Be responsible for data analysis, training, evaluation and related deployment systems\n",
      "Utilize machine learning technologies for speech processing\n",
      "Non-stop looking for new state-of-the-art approaches and open-mind to the differences\n",
      "Stay on time and deliver exceptional products\n",
      "==================================================\n",
      "Rank #5\n",
      "Score: 0.1817\n",
      "Document: Title: Software Engineer Intern\n",
      "Job level: internship\n",
      "Working type: fulltime\n",
      "Company: Rakuna\n",
      "Qualifications & Skills:\n",
      "Commit at least 6-months as full-time intern may have the opportunity to be offered full-time position post-internship if shown excellency at work.\n",
      "Currently enrolled in a Bachelor s program in Computer Science, Information Technology or a related technical field.\n",
      "Experience of coding in one of the following programming languages including but not limited to: Ruby, C++, Java, Python, Go.....\n",
      "Demonstrated interest and ability to learn other coding languages as needed.\n",
      "Developed communication skills, and adequate ability to speak and write in English.\n",
      "Effective teamwork, project management, creative problem-solving.\n",
      "strong communication skills.\n",
      "Technology internship experience or work experience e.g: research assistant, teaching assistant, personal projects, etc.\n",
      "Interested in or love the startup-like environment, want to challenge self and aim for a leadership prospect.\n",
      "\n",
      "Responsibilities:\n",
      "Assist in building and/or managingproduct pipelines including planning, development, and maintenance.\n",
      "Analyze information and evaluate results to choose the best solution to effectively solve problems.\n",
      "Provide quality assurance QA support through product testings.\n",
      "Work with peers, managers, and teams to create and support core functional teams - Sales Marketing, Quality and Customer Success, and Operations.\n",
      "Learn in-depth about how to create a product in a start-up environment.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for result in rerank_results.results:\n",
    "    result.document = document_list[result.index]\n",
    "\n",
    "\n",
    "for idx, result in enumerate(rerank_results.results, 1):\n",
    "    print(f\"Rank #{idx}\")\n",
    "    print(f\"Score: {result.relevance_score:.4f}\")\n",
    "    print(f\"Document: {result.document}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7270187,
     "sourceId": 11593735,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
