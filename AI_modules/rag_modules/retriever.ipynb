{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189a3ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource module not available on Windows\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.huggingface import HuggingFaceLLM, HuggingFaceInferenceAPI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "from llama_index.core import  VectorStoreIndex, StorageContext, QueryBundle, load_index_from_storage, Settings\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc5dafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(r\"C:\\Users\\leduc\\OneDrive\\Desktop\\NLP\\grab-capstone-project\\NavigaTech\\AI_modules\\.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e48c7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leduc\\AppData\\Local\\Temp\\ipykernel_17196\\2120198261.py:1: DeprecationWarning: Call to deprecated class HuggingFaceInferenceAPI. (Deprecated in favor of `HuggingFaceInferenceAPI` from `llama-index-llms-huggingface-api` which should be used instead.)\n",
      "  llm = HuggingFaceInferenceAPI(model_name=\"mistralai/Mistral-7B-Instruct-v0.2\", token=os.environ[\"HF_TOKEN\"])\n",
      "c:\\Python311\\Lib\\site-packages\\beartype\\_util\\error\\utilerrwarn.py:67: BeartypeModuleUnimportableWarning: Ignoring module \"onnx\" importation exception:\n",
      "    ImportError: DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed.\n",
      "  warn(message, cls)\n",
      "c:\\Python311\\Lib\\site-packages\\beartype\\_util\\error\\utilerrwarn.py:67: BeartypeModuleUnimportableWarning: Ignoring module \"onnx\" importation exception:\n",
      "    ImportError: DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed.\n",
      "  warn(message, cls)\n",
      "c:\\Python311\\Lib\\site-packages\\beartype\\_util\\error\\utilerrwarn.py:67: BeartypeModuleUnimportableWarning: Ignoring module \"onnx\" importation exception:\n",
      "    ImportError: DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed.\n",
      "  warn(message, cls)\n",
      "c:\\Python311\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceInferenceAPI(model_name=\"mistralai/Mistral-7B-Instruct-v0.2\", token=os.environ[\"HF_TOKEN\"])\n",
    "embbeding_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embbeding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d14cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(persist_dir=r\"C:\\Users\\leduc\\OneDrive\\Desktop\\NLP\\grab-capstone-project\\NavigaTech\\AI_modules\\rag_modules\\rag_db\")\n",
    "index =  load_index_from_storage(storage_context = storage_context)\n",
    "# index =  load_index_from_storage(storage_context = storage_context, index_id=r\"9f77b52b-e01e-4634-9def-8d5c9f52363a\")\n",
    "nodes = list(index.docstore.docs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954398d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_retriever = index.as_retriever(similarity_top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d395d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = QueryFusionRetriever(\n",
    "    [\n",
    "        base_retriever,\n",
    "        BM25Retriever.from_defaults(\n",
    "            docstore=index.docstore, similarity_top_k=20, language=\"english\"\n",
    "        ),\n",
    "    ],\n",
    "    num_queries=1,\n",
    "    use_async=True,\n",
    "    retriever_weights=[0.7, 0.3],\n",
    "    mode=\"dist_based_score\",\n",
    "    similarity_top_k=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e7a5e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "LE DUC TAI\n",
    "Phone:\n",
    "Linkedin:\n",
    "Email: \n",
    "Github: \n",
    "ORCID:\n",
    "Google Scholar:\n",
    "SUMMARY\n",
    "\n",
    "0783349553\n",
    "Duc Tai Le\n",
    "leductai2201@gmail.com\n",
    "NBTailee\n",
    "Duc Tai Le\n",
    "Le Duc Tai\n",
    "\n",
    "As an AI Engineer intern specializing in Large Language Models (LLMs), I want to gain hands-on experience fine-\n",
    "tuning  and  optimizing  NLP,  Generative  AI  models  and  RAG  for  specific  applications.  I  worked  on  building  web\n",
    "applications,  model  finetuning.  Additionally,  I  also  want  to  explored  cutting-edge  techniques  like  prompt\n",
    "engineering and transfer learning. I have some experience with HuggingFace, YOLO, Pytorch, Flask, NodeJS and\n",
    "ReactJS.\n",
    "\n",
    "EDUCATION\n",
    "\n",
    "Currently Studying Bachelor of Computer Science\n",
    "University of Information Technology of Ho Chi Minh city (UIT)\n",
    "\n",
    "Machine Learning team member of AI club of UIT.\n",
    "\n",
    "LANGUAGES\n",
    "\n",
    "IELTS: 6.5 overall\n",
    "\n",
    "RESEARCH PAPERS & PUBLICATIONS\n",
    "\n",
    "GPA: 3.5\n",
    "\n",
    "MMLabUIT at CoMeDi Shared Task: Text Embedding Techniques versus Generation-Based NLI for\n",
    "Median Judgment Classification.\n",
    "\n",
    "      Conference: COLING ranking A\n",
    "\n",
    "Classification of racial stereotypes in Spanish With Ensemble Learning Methods and BERT-based\n",
    "Adapter Head.\n",
    "      Conference: IberLEF\n",
    "\n",
    " AWARDS & CERTIFICATIONS\n",
    "\n",
    "Top 3rd CoMeDi competition track 1 of COLING 2025 conference\n",
    "Top 8th in SemEval 2025 track 9 The Food Hazard Detection Challenge of ACL conference.\n",
    "Top 9th  DETEST-Dis IberLef 2024 competition track 1 of SEPLN conference\n",
    "Top 34th in AI City Challenge 2024 competition Track 5\n",
    "Data Scientist Associate Certificate - Datacamp\n",
    "IBM Data Science Specialization - IBM\n",
    "Machine Learning Specialization - DeepLearning.io\n",
    "SQL (Intermediate) Certificate - Hackerrank\n",
    "\n",
    "SKILLS & TECH STACK\n",
    "\n",
    "AI/ML: Pytorch, Tensorflow, scikit-learn, pandas, numpy, matplotlib.\n",
    "NLP/LLM & RAG/Agent: HuggingFace, LLamaIndex, LangChains, NLTK, Gemini LLM, CohereAI.\n",
    "\n",
    "Developing multi-query system with different techniques to enhance retrieved content quality.\n",
    "Can apply Prompt engineering in AI solution with prompt format, prompt techniques.\n",
    "Conducting new NLP approaches for many problem in real world.\n",
    "Use different LLM in one system with flexible purpose.\n",
    "Computer Vision: YOLO(Ultralytics), EasyOCR, Roboflow.\n",
    "\n",
    "Developing high accuracy and inference speed detection, OCR real-time system.\n",
    "\n",
    "Back-End: Flask, NodeJS, Postman.\n",
    "\n",
    "have pretty solid knowledge in CRUD app and intermediate in RESTapi.\n",
    "Can create end-to-end project integrated with AI/ML solutions.\n",
    "\n",
    "Front-End: ReactJS, Redux, Streamlit, Gradio, MaterialUI.\n",
    "\n",
    "have solid skill in developing web UI based on requirements.\n",
    "\n",
    "Database: MongoDB, PinconeDB, ChromaDB, MySQL.\n",
    "Research skills: Google Scholar, ACL anathology.\n",
    "\n",
    "Have more than 1 years experience in researching about NLP/LLM topics and also have research\n",
    "papers.\n",
    "\n",
    "\fPROJECTS\n",
    "\n",
    "UIT Agent with multi flow answering system\n",
    "\n",
    "Small Talk Detection: Implements a system to distinguish casual conversation queries and route them\n",
    "appropriately.\n",
    "Dynamic Query Transformation: Utilizes HyDE Query Transformation to enhance search performance for\n",
    "complex queries.\n",
    "Hybrid Search Integration: Combines BM25 and Semantic Search for precise and contextually relevant\n",
    "results.\n",
    "Metadata Filtering and Retrieval: Ensures accurate historical context retrieval through metadata filtering.\n",
    "Query Re-ranking: Optimizes search result order based on relevance and context using reranking\n",
    "mechanisms.\n",
    "HuggingFace LLM Integration: Leverages HuggingFace for advanced natural language understanding and\n",
    "response generation.\n",
    "Scalable Architecture: Multi-stage query pipeline with modular end-to-end resolution.\n",
    "Tech Stack: Pinecone, LlamaIndex, Hugging Face, Gemini, Cohere, Flask, ReactJS.\n",
    "\n",
    "AI information retrieval Web Application\n",
    "\n",
    "Text Processing: Extracted token length, conducted sentiment analysis, emotion classification, and\n",
    "summarized text in English and Vietnamese. Fine-tuned \"phoBART-syllable-base\" for superior Vietnamese\n",
    "text summarization with QLora and Quantization techniques.\n",
    "Image Analysis: Implemented object detection, optical character recognition (OCR), and image captioning\n",
    "using zero-shot learning models from Ultralytics and EasyOCR.\n",
    "Audio Recognition: Developed capabilities for audio-to-text conversion and sound classification.\n",
    "\n",
    "RAG chatbot for course information\n",
    "\n",
    "Designed and implemented a Retrieval-Augmented Generation (RAG) application utilizing the Vietstral-7B\n",
    "model from HuggingFace.\n",
    "Integrated advanced LangChains and CohereAI capabilities to enhance model performance.\n",
    "Utilized ChromaDB as the retrieval database, employing Cosine similarity and Reranker techniques for\n",
    "efficient and accurate data retrieval from large datasets.\n",
    "Enabled context-aware responses by feeding retrieved data into the LLM.\n",
    "Developed an intuitive user interface for the application using Gradio.\n",
    "\n",
    "Median Judgment Classification in 7 Languages\n",
    "\n",
    "Advanced NLP Techniques: Implemented stacked embeddings, averaged embeddings, and Natural\n",
    "Language Inference (NLI) with BERT-based and generative models.\n",
    "Custom Token & Data Processing: Enhanced model performance through custom tokens, data\n",
    "augmentation, and Named Entity Recognition (NER)-based preprocessing.\n",
    "Evaluation & Optimization: Achieved 0.596 Krippendorff’s α score, significantly improving baseline\n",
    "classification results.\n",
    "Machine Learning & NLP: BERT, RoBERTa, XLM-R, BART, Cosine Similarity, NLI\n",
    "Data Processing: Stratified K-Fold Cross-Validation, Lemmatization, Text Expansion\n",
    "Development Frameworks: Hugging Face, PyTorch, TensorFlow\n",
    "Computational Resources: Fine-tuned models on Kaggle P100 GPUs using AdamW & AdaFactor optimizers\n",
    "\n",
    "Stereotype classification in Spanish\n",
    "\n",
    "Finetuning BETO, RoBERTa, XLM-RoBERTa, mDeBERTa-v3, DeHATEbert.\n",
    "Finetuning XLM-RoBERTa-twitter-hate.\n",
    "Using ensemble learning methods: Hard-voting, Soft-voting, Stacking.\n",
    "Make use of Adapter Head to improve performance.\n",
    " Apply Handcraft-Features for BERT-based models.\n",
    " Finetuning SVM, RandomForest with GridSearchCV, cross-validation.\n",
    "\n",
    "Detecting Violation of Helmet Rule for Motorcyclists\n",
    "\n",
    "Helmet Rule Violation Detection: Developed an AI-powered system to detect motorcyclist helmet\n",
    "violations using state-of-the-art object detection models.\n",
    "Addressed Key Challenges: Tackled unbalanced data and small object detection issues by fine-tuning\n",
    "YOLOv8 with a p2 head and implementing the SAHI algorithm to enhance precision and recall.\n",
    "Advanced Object Detection Models: Fine-tuned Real-Time DETR for accurate object detection and\n",
    "integrated the latest YOLOv9 for improved efficiency.\n",
    "Deep Learning & Computer Vision: YOLOv8, YOLOv9, DETR, SAHI algorithm\n",
    "Model Optimization: Fine-tuning, small object detection enhancement, precision-recall improvement\n",
    "Development Frameworks: PyTorch, TensorFlow, OpenCV\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf91c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_rerank = CohereRerank(model=\"rerank-english-v3.0\" ,api_key=os.environ[\"COHERE_API_TOKEN\"], top_n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30c4a4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** ac64db0a-86a4-4dfb-9f69-3827ae063e99<br>**Similarity:** 1.0085090012298172<br>**Text:** Candidates should have hands-on experience with feature engineering pipelines that enhance the contextual accuracy of LLMs for long-sequence, multi-turn conversational modeling.Advanced experience with embedding manipulation techniques, such as masked token prediction, continuous token augmentation, and variational encoding, to dynamically adjust feature weights based on semantic proximity, particularly in dense retrieval tasks.Mastery of reinforcement learning paradigms for adaptive LLM fine-tuning, utilizing reward functions derived from similarity scores and relevance metrics in high-frequency retrieval systems to improve query-response fidelity.Complex Vector Database Integration & Feature Structuring for Semantic Similarity:Extensive experience designing and engineering feature vectors for semantic search optimization within vector databases (e.g., Pinecone, Faiss, Weaviate) and high-dimensional vector space management. Candidates should have technical proficiency in high-dimensional distance metrics such as cosine similarity, Euclidean distance, and inner product, optimized for specific retrieval tasks.Expert in structuring custom embeddings and vector schemas that enhance semantic search precision by capturing latent contextual signals through PCA, UMAP, and t-SNE techniques. Expertise in embedding normalization, vector scaling, and dimension reduction to balance retrieval speed and vector alignment accuracy.Ability to construct and manipulate KNN (k-nearest neighbor) indices, such as Hierarchical Navigable Small World (HNSW) graphs and IVF (Inverted File) structures, to optimize high-throughput search scenarios. Experience in designing vector clusters using k-means and density-based algorithms, enhancing semantic granularity across vectorized search spaces.High-Precision Semantic & Similarity Search EngineeringMastery in designing and implementing hybrid search architectures that combine dense embeddings with sparse vectors (BM25, TF-IDF) for enhanced retrieval relevance across semantic layers. Experience integrating hybrid dense-sparse models in RAG systems, ensuring that each query achieves optimal precision and recall based on adaptive similarity metrics.Expert in developing and tuning semantic similarity metrics, particularly cosine similarity, for real-time high-volume similarity search tasks. This includes leveraging cosine-similarity-based scoring mechanisms in similarity search pipelines to refine response ranking and ensure contextual relevance.Experience constructing cosine similarity feature transformations to boost search accuracy in query expansion contexts, utilizing cosine-based re-ranking and feature recalibration strategies that enable real-time refinement of relevance scoring.Specialized RAG-Specific Feature Engineering For Retrieval OptimizationExpertise in engineering feature pipelines within RAG architectures, specifically for enhancing query augmentation and retrieval conditioning based on multi-stage RAG frameworks. Candidates should have experience structuring bi-encoder and cross-encoder embeddings to support context-dependent token weighting and real-time relevance adjustments.Advanced experience in developing dynamic re-ranking mechanisms, integrating cosine and dot-product similarity metrics within RAG query layers for optimized retrieval at both coarse-grained and fine-grained levels. Expert in implementing memory-efficient vector stores and cached retrieval pathways that ensure low-latency response in high-frequency applications.Ability to optimize retrieval via custom feature weighting models, which selectively prioritize features based on semantic relevance derived from query intent prediction models, response context preservation, and adaptive relevance feedback mechanisms.Embedding & Similarity Feature Optimization With Real-Time SystemsExpert in designing high-dimensional embedding structures that support rapid cosine similarity calculations, especially within sparse or sparse-dense hybrid retrieval models. Familiarity with optimization techniques that reduce the computational load of similarity calculations in production-grade environments.Expertise in constructing advanced indexing schemes (e.g., IVF, PQ) that facilitate high-speed similarity search across large vector stores while minimizing precision loss. Skilled in implementing and tuning complex scoring layers, including custom cosine similarity scoring models that account for context-switching in multi-turn LLM interactions.Demonstrated capability in applying real-time re-ranking protocols within RAG-based systems, incorporating cosine-similarity-driven reordering, redundancy reduction in query results, and relevance fine-tuning based on LLM contextual embeddings.In addition to AI architecture and AI development, you will be responsible for engineering and implementingend-to-end AI pipelines, ensuring proper integration of these AI models into back-end systems developed usingDjango. You will be heavily i...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** e4506d74-8a55-4b01-aba0-6dcc5a608aff<br>**Similarity:** 0.7316047565032242<br>**Text:** This role will involve working on various projects, including text analysis, language modeling, and model deployment in production environments. You will also be instrumental in applying generative models for creative and business purposes, such as text generation and data augmentation.Primary Responsibilities/Essential FunctionsNatural Language Processing (NLP):Lead the design and implementation of advanced NLP models for tasks such as text classification, named entity recognition (NER), topic modeling, sentiment analysis, and language translation.Apply cutting-edge deep learning techniques like Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTMs), and transformer models (e.g., BERT, GPT) for complex NLP tasks.Leverage pre-trained language models, word embeddings (Word2Vec, GloVe, FastText), and fine-tune them to meet custom business requirements.Generative AI:Apply Generative AI techniques, such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformer-based models (e.g., GPT-3, T5), to develop solutions for text generation, data augmentation, and other creative use cases.Explore innovative applications of Generative AI in content creation, including summarization, question generation, and dialogue systems.Stay up-to-date with the latest advancements in Generative AI, and integrate them into existing pipelines to enhance model performance and functionality.Collaborate with cross-functional teams to explore new business applications for generative models, such as synthetic data generation for model training or content generation for marketing.Supervised Learning:Develop and optimize machine learning models using supervised learning techniques such as regression, classification, Support Vector Machines (SVMs), and decision trees.Evaluate models using performance metrics such as accuracy, precision, recall, F1 score, and use cross-validation to ensure model robustness.Unsupervised Learning:Use clustering algorithms, such as K-means and hierarchical clustering, and dimensionality reduction techniques like Principal Component Analysis (PCA) to uncover hidden patterns in data.Implement anomaly detection models to identify rare events or outliers in datasets, supporting business intelligence and decision-making.Deep Learning:Lead the design and deployment of deep learning models using Convolutional Neural Networks (CNNs), RNNs, LSTMs, and transformers to handle complex tasks in both NLP and Generative AI.Optimize and fine-tune deep learning architectures to improve accuracy, performance, and scalability of models in production.Model Deployment and MLOps:Deploy machine learning models into production using cloud platforms such as Azure ML, ensuring scalability and performance.Implement MLOps best practices, including CI/CD pipelines, model versioning, and automated retraining using tools like MLflow, Kubeflow, and Azure ML Pipelines.Monitor models post-deployment, track model performance, identify drift, and retrain models as necessary to maintain their relevance and accuracy.QualificationsEducation:Master’s or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering, or a related field.Experience:5+ years of experience in machine learning, with a focus on Natural Language Processing (NLP) and Generative AI.Extensive experience with deep learning frameworks such as TensorFlow, Keras, or PyTorch for building and deploying models.Proven expertise in deploying models to production environments using cloud platforms such as Azure ML, AWS, or GCP.Familiarity with MLOps practices, including CI/CD, model versioning, and automated retraining.Technical Skills:Proficiency in Python and machine learning libraries such as scikit-learn, TensorFlow, PyTorch, Keras, Hugging Face Transformers, NLTK, and SpaCy.Expertise in NLP techniques, including tokenization, word embeddings, transformers (e.g., BERT, GPT), and sequence models like RNNs and LSTMs.Experience with Generative AI models such as GANs, VAEs, and transformers (e.g., GPT-3, T5) for tasks like text generation and data augmentation.Experience with cloud platforms for model deployment, including Azure ML, AWS, or GCP.Familiarity with MLOps tools such as MLflow, Kubeflow, and Azure ML Pipelines for tracking, monitoring, and automating ML models.Leadership and Soft Skills:Excellent communication skills with the ability to explain complex technical concepts to non-technical stakeholders.Collaborate with data engineers, product managers, and other stakeholders to translate business requirements into machine learning solutions.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 54f713ab-35a5-4399-830a-a6fe346569c2<br>**Similarity:** 0.5833710331518951<br>**Text:** The ideal candidate will be well-versed in the latest Large Language Model (LLM) technologies and have a strong background in data engineering, with a focus on Retrieval-Augmented Generation (RAG) and knowledge-base techniques.  This role sits in the AI COE within DX Tech & Digital. As a AI/LLM Data Engineer (you will report into the Director, AI Solutions & Development who oversees the AI COE.You will work on highly visible strategic projects, collaborating with cross-functional teamsto define requirements and deliver high-quality AI solutions.The ideal candidate will have a passion for Generative AI and LLMs, with a proven track record of delivering innovative AI applications.ResponsibilitiesDesign, implement, and maintain an end-to-end multi-stage data pipeline for LLMs, including Supervised Fine Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) data processesIdentify, evaluate, and integrate diverse data sources and domains to support the Generative AI platformDevelop and optimize data processing workflows for chunking, indexing, ingestion, and vectorization for both text and non-text dataBenchmark and implement various vector stores, embedding techniques, and retrieval methodsCreate a flexible pipeline supporting multiple embedding algorithms, vector stores, and search types (e.g., vector search, hybrid search)Implement and maintain auto-tagging systems and data preparation processes for LLMsDevelop tools for text and image data crawling, cleaning, and refinementCollaborate with cross-functional teams to ensure data quality and relevance for AI/ML modelsWork with data lake house architectures to optimize data storage and processingIntegrate and optimize workflows using Snowflake and various vector store technologiesRequirementsMaster's degree in Computer Science, Data Science, or a related field3-5 years of work experience in data engineering, preferably in AI/ML contextsProficiency in Python, JSON, HTTP, and related toolsStrong understanding of LLM architectures, training processes, and data requirementsExperience with RAG systems, knowledge base construction, and vector databasesFamiliarity with embedding techniques, similarity search algorithms, and information retrieval conceptsHands-on experience with data cleaning, tagging, and annotation processes (both manual and automated)Knowledge of data crawling techniques and associated ethical considerationsStrong problem-solving skills and ability to work in a fast-paced, innovative environmentFamiliarity with Snowflake and its integration in AI/ML pipelinesExperience with various vector store technologies and their applications in AIUnderstanding of data lakehouse concepts and architecturesExcellent communication, collaboration, and problem-solving skillsAbility to translate business needs into technical solutionsPassion for innovation and a commitment to ethical AI developmentExperience building LLMs pipeline using framework like LangChain, LlamaIndex, Semantic Kernel, OpenAI functionsFamiliar with different LLM parameters like temperate, top-k, and repeat penalty, and different LLM outcome evaluation data science metrics and methodologiesPreferred SkillsExperience with popular LLM/ RAG frameworksFamiliarity with distributed computing platforms (e.g., Apache Spark, Dask)Knowledge of data versioning and experiment tracking toolsExperience with cloud platforms (AWS, GCP, or Azure) for large-scale data processingUnderstanding of data privacy and security best practicesPractical experience implementing data lakehouse solutionsProficiency in optimizing queries and data processes in Snowflake or DatabricksHands-on experience with different vector store technologiesBenefitsUS employees benefit package<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** d703c39b-a3fd-43de-a4df-80bad5bd9d43<br>**Similarity:** 0.5716868916599451<br>**Text:** Your work will focus on enhancing user experiences by embedding natural language understanding into practical applications and improving real-time data processing.Key Responsibilities:Develop and optimize workflows for RAG and NLP models.Build and maintain scalable vector databases for AI applications.Design and implement applications that integrate with large language models via APIs, such as ChatGPT, for user interaction, query processing, and response generation.Collaborate with cross-functional teams to integrate AI capabilities into various systems.Conduct experiments to fine-tune models and enhance their performance.Stay updated on the latest trends and advancements in AI technologies.Required Qualifications:Bachelor’s degree in Computer Science, AI, or a related field.1-3 years of experience working with RAG, NLP, and vector databases.Proficiency in Python and experience with frameworks such as PyTorch, TensorFlow, or Hugging Face.Experience developing applications that interact with large language models.Familiarity with vector databases (e.g., Pinecone, Weaviate).Experience with real-time data retrieval and processing through APIs like ChatGPT.Strong understanding of natural language processing techniques and text embedding models.Desired Qualifications:Advanced degree in a relevant field.Experience deploying AI models in production environments.Familiarity with reinforcement learning for large language models and cloud platforms.Experience with frameworks like LangChain or Pydantic AI, or custom LLM frameworks.Experience with RAG applications, including locally hosted or public LLM API services.Experience with LLM tool calling and fine-tuning models for tasks like sentiment analysis and text classification.Expertise in language model prompt engineering.If you’re excited about building AI-driven applications and working with cutting-edge technologies, we’d love to hear from you!<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 3c9109f0-a4fc-4f61-a3a2-2aecd7e261c6<br>**Similarity:** 0.4592968936443579<br>**Text:** TensorFlow Lite) is a plusExperience building ML models with time-series or sequential data (such as NLP), especially for long time sequences and real-time processing scenarios. Experience working with sensor data is a plusFamiliarity with reinforcement learning (RL), computational graphs, and/or graph neural networks is a plus.Knowledgeable in techniques to optimize ML models for inference in compute-limited scenarios (i.e. model distillation, pruning, dimensionality reduction, feature selection, parallelization)Familiar deploying models for fast, efficient inference on compute accelerators (TPUs or NPUs).Proficient in designing, implementing, and maintaining robust ML pipelines for end-to-end model lifecycle management. Experience benchmarking multiple models is a plus.Familiar deploying models in containerized settings, such as Docker. Knowledge of Kubernetes and/or Docker Swarm is a plus. Familiar with SQL or similar database systems (such as MySQL, PostgreSQL, MongoDB)Proficient in Git or other version control systemsFamiliar with cloud platforms such as AWS, Azure, or Google CloudExperience working with LLMs/RAG is a plus, especially in building a company knowledgebase, chatbot, or for data analysis/summarization. Familiarity with Agile methodologies and experience in collaborative, cross-functional teamsAnalytical thinker with the ability to solve complex problems efficientlyExcellent communication skills to articulate technical issues, solutions, and progress effectivelyAdaptability to learn new technologies and adapt to evolving project requirementsStrong team player mindset, comfortable sharing knowledge and collaborating within a team environmentFamiliarity with Agile methodologies and experience in collaborative, cross-functional teamsAnalytical thinker with the ability to solve complex problems efficientlyMeticulous attention to detail in writing clean, maintainable code and designing robust database architecturesExcellent communication skills to articulate technical issues, solutions, and progress effectivelyAdaptability to learn new technologies and adapt to evolving project requirementsBenefitsDirect impact on product and cultureComprehensive benefits package including Medical, Dental, Vision, Life Insurance, Disability, Transportation benefit, Health and Wellness benefit, and more401k plan with employer matchingEquityCompetitive salary and bonus opportunitiesDynamic and inclusive work environmentOpportunities for growth and professional developmentAccess to Greentown Labs' extensive network of cleantech startupsLearn How We ThinkLearn about our startup journey: Our JourneyHow we're combating climate change: AI-Powered Climate TechA customer story: Ben & Jerry's uses H2Ok's precision automation to cut time & water usageWhy H2Ok Innovations?Impact:Work on cutting-edge AI and sensor tech that’s already transforming how factories use water, energy, and chemicals. Join a tight-knit, ambitious team where your contributions can reshape the industry.Growth:Join a fast-growing startup where you’ll have the opportunity to shape our content strategy. We value fostering extraordinary growth in our teammates.Innovative Culture:Work in a high-performance environment that values empowerment, creativity, ownership, autonomy, innovation, excellence, passion, and continuous growth.Sustainability Focus:Play a key role in promoting sustainability and Industry 4.0 advancements in manufacturing.Build the intelligence layer powering the next generation of industrial efficiency – with a team that moves fast and delivers real impact.At H2Ok Innovations, we’re committed to diversity, equity, and inclusion, and we encourage applicants from all backgrounds to apply.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 849337b7-1136-4d28-87d4-ca5c3bb90884<br>**Similarity:** 0.45506180455878437<br>**Text:** Working collaboratively, we advance missions and careers through a focus on honesty, integrity, and dependability. We continuously look for talent, excited to join that effort. To learn more about our exciting organization, please visit us at www.unissant.com.We are seeking anAI-ML Developerto join our team and support our Department of Homeland Security (DHS) customer in theWashington DCmetro area.Essential Duties And ResponsibilitiesAs the AI/ML developer, an ideal candidate will be part of a team to provide consultative, architectural, program, and engineering support for a federal customerDrive a big data approach to execute government requirements to manage and enrich data to gather new insights.Develop, train, and deploy advanced AI/ML models, including generative AI techniques like large language models (LLMs).Design and implement innovative AI solutions to address complex business challenges, such as natural language processing.Optimize model performance, ensuring accuracy, efficiency, and scalability.Develop, train, deploy and maintain user-friendly AI applications and interfaces, including chatbots, virtual assistants, and generative content tools.Collaborate with cross-functional teams to integrate AI solutions into existing systems and workflows.Stay up to date with the latest advancements in AI/ML and emerging technologies, such as generative AI and reinforcement learning.Conduct research and experiments to explore new AI techniques and applications, including prompt engineering, Advanced RAGs and fine-tuning LLMs.Ensure compliance with data privacy and security regulations, especially when dealing with sensitive data and generative AI outputs.Responsible for briefing the benefits and constraints of technology solutions to technology partners, stakeholders, team members, and senior levels of managementWork Experience5+ years of experience in the Information Technology field focusing on AI/ML engineering projects, MLOps/DevSecOps and technical architecture specifically.Experience in architecture & design, with a preference for 3 years of experience deploying production enterprise applications on-prem or on cloud.Experience with classification, forecasting, transformers, and generative models.Experience in data visualization using tools like Plotly and Matplotlib.Experience in large-scale, high-performance enterprise big data application deployment and solution architecture on complex heterogeneous environment.Experience with machine learning and generative AI frameworks.Experience with natural language processing techniques (e.g., text classification, language generation).Solid understanding of any of the cloud platforms (e.g., AWS, Azure, GCP) and deployment strategies.Job SkillsDatabase Knowledge: Knowledge of database systems (e.g., SQL, NoSQL) and data warehousing concepts.Generative AI Models: Proficiency in developing, deploying, and fine-tuning generative AI models, including large language models (LLMs).Multi-Agent / Agentic-AI Models: Proficiency in building Agentic-AI systems using tools such as LangChain Agents and Crew-AI.Cloud AI-ML Resource Knowledge: Knowledge of AWS SageMaker, Bedrock, Amazon Q, Amazon Elastic Inference.Programming Languages: Strong proficiency in programming languages such as Python, R, Java, and C/C++.Front-end Development: Proficiency in any front-end development technologies (e.g., React, Angular, Vue.js, HTML, CSS, JavaScript).Data Analytics: Expertise with libraries such as Pandas and NumPy for data manipulation and exploration.ML Frameworks: Proficiency in ML Modeling concepts and frameworks like Scikit-Learn, TensorFlow, Keras, PyTorch, and others.Data Preprocessing: Strong skills in data encoding, normalizing, and regularizing to prepare datasets for ML models.Deep Learning: Solid understanding of deep learning architectures such as CNNs (Convolutional Neural Networks), RNNs (Recurrent Neural Networks), LSTMs (Long Short-Term Memory networks), and GANs (Generative Adversarial Networks), with the ability to apply them to real-world data sets and problems.Anomaly Detection: Familiarity with anomaly detection techniques and deep learning models.Cloud Platforms: Solid understanding of cloud services, such as AWS, Azure, or GCP, and deployment strategies.EducationBachelor's degree in computer science, Information Technology Management or Engineering is preferred. Alternative work-related experience, Military Duty, and/or specialized or higher education may be substituted.Certificates, Licenses And RegistrationsThis federal program requires the candidates to be a United States Citizen.DHS Public Trust and/or DOD TS clearance is preferred.Qualified applicants may be subject to a security investigation and must meet minimum qualifications for access to classified information.Any related systems engineering, or related technical certifications are desired.AWS/Azure/GCP AI/ML certifications are preferred but not required.Communication SkillsExcellent verbal and...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** d15af210-bf4e-42c8-beb6-61f0e134026c<br>**Similarity:** 0.44675495397731413<br>**Text:** This position is ideal for individuals seeking a career in senior AI engineering and interested in working with a pioneering company in enterprise AI solutions.In this position, you will engage heavily in the development ofnatural language processing (NLP)models,large language models (LLMs)likeRAG,DistilBERT,BERT,RoBERTa, andLLaMA, as well asdeep reinforcement learningtechniques to create AI systems that learn, adapt, and evolve. You will be directly responsible for building AI pipelines, refining training methodologies, and implementing real-time solutions, ensuring they are secure, reliable, and optimized for performance in live cloud environments. In this role, you will be at the forefront of Flow's R&D initiatives, engaging in the entire AI development lifecycle. You’ll design, implement, and refine AI and deep learning models using state-of-the-art frameworks such asTensorFlow,PyTorch, and Keras, with a focus on Natural Language Processing (NLP), Large Language Models (LLMs) includingRAG, BERT, DistilBERT, RoBERTa, and LLaMA, and advanced neural architectures dedicated to Flow’s SaaS AI sales solutions. You’ll leverage these models in a cloud-based infrastructure, ensuring they are optimized, scalable, and capable of handling high-availability production loads.LLM-Specific Feature Optimization For Enhanced Contextual RelevanceCandidates must demonstrate extensive previous experience inadvanced feature engineeringfor optimizing large language models (LLMs) and Retrieval-Augmented Generation (RAG) architectures, specifically within high-dimensional vectorized environments. Expertise should encompass the following technical capabilities:Expert in engineering token embeddings, positional encodings, and contextual attention mechanisms tailored to transformer-based architectures (GPT, T5, BERT) within RAG frameworks.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 5d86fa6f-2598-418f-aad7-7e7a56046f4c<br>**Similarity:** 0.423576019665833<br>**Text:** ACTIVE TS/SCI SECURITY CLEARANCE AND POLYGRAPH REQUIRED**Position Overview:D2 Consulting is seeking a highly skilledAI/LLM Engineerwith an activeTS/SCI clearance and CI polygraphto lead the design, deployment, and optimization of an on-premises Large Language Model (LLM) solution. This role involves architecting and implementing secure, scalable AI systems capable of ingesting, processing, and analyzing large datasets — including structured and unstructured data comprisingmillions of records.You will work alongside cross-functional teams supporting critical missions within the Intelligence Community, applying cutting-edge AI/ML techniques to drive insights and decision-making in secure environments.Key Responsibilities:Design and implement secure, on-premises LLM infrastructure and pipelines tailored to mission needsEvaluate, fine-tune, and deploy open-source or custom LLMs within air-gapped environmentsDevelop and manage data pipelines for ingesting and processing structured and unstructured datasets at scaleApply NLP, ML, and data science techniques to extract insights from massive datasets (millions+ records)Collaborate with analysts, engineers, and mission stakeholders to shape AI capabilities around operational requirementsEnsure compliance with security and data governance standards for classified environmentsMonitor model performance, implement updates, and optimize compute usageBasic Qualifications:Active TS/SCI clearance with CI Polygraph5+ years of experience in AI/ML engineering, data science, or software developmentHands-on experience deploying or fine-tuning LLMs (e.g., LLaMA, Mistral, GPT-NeoX, BERT, etc.)Experience with on-prem or air-gapped AI/ML deployments, including containerized or GPU-based environmentsStrong proficiency in Python and common ML/NLP libraries (e.g., Hugging Face Transformers, PyTorch, LangChain)Experience working with large datasets (millions of records), including ETL and data transformation pipelinesSolid understanding of system architecture, data privacy, and secure computing practicesPreferred Qualifications:Experience deploying quantized models for performance optimization (e.g., using llama.cpp, ggml, gguf)Familiarity with GPU server infrastructure (e.g., NVIDIA A100/RTX, CUDA) or multi-node compute setupsKnowledge of cloud-to-on-prem transition architecturesBackground in supporting Intelligence Community or DoD missionsWhy Join D2 Consulting?As aVeteran-Owned Small Business, D2 Consulting delivers enterprise IT services to the U.S.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 1f346c87-d9e2-4875-bd31-3e62a3642b74<br>**Similarity:** 0.4030309449517275<br>**Text:** Courage? Always.At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.Join us.About The TeamThe Governance and Experience Algorithm team was established in September 2020 and its main job is to support the following businesses with the most advanced AI technology：Combat any kinds of risks/violations issues in E-commerce scenarios.Build an E-commerce ecosystem and improve platform service capabilitiesResponsibilities:Responsible for identifying algorithms for risk/violation/low-quality issues in e-commerce scenarios such as products, shopping cart short videos, and live streaming with products.Responsible for mining and identifying algorithms to detect fraudulent behaviors and identify risky, violated, or low-quality merchants and creators.Responsible for optimizing algorithms for large-scale brand libraries, products, and content deduplication/clustering.Responsible for data construction, instruction fine-tuning, CoT, alignment, and other work for large models in the e-commerce domain, aiming for ultimate effect optimization in the e-commerce domain.Responsible for exploring reinforcement learning and operational research algorithms in intelligent dispatching and intelligent audit scheduling to improve audit quality and efficiency.What You Will Do:Optimize various basic algorithms such as NLP, vision, multimodal, search, graph, LLM, etc. to provide support for governance business, explore cutting-edge technologies, and apply them to e-commerce business scenarios.Streamline the optimization and iteration process for computer vision models in e-commerce settings, including fine-grained classification of product images, product object recognition, product subject recognition, feature extraction, logo detection, brand recognition, etc.Optimize video classification, multimodal content mining, and multimodal content understanding of e-commerce short videos and live broadcasts, and optimize the e-commerce short video shopping experience.Optimize the risk identification model related to text content in e-commerce scenarios, such as product copywriting, picture text, and voice descriptions.Optimize the risk mining algorithm for comments, reports, and other public opinion content related to products/short videos/live broadcasts, and improve the platform governance effect.Responsible for the research of large-scale multimodal (vision, speech, natural language, etc.) algorithms and their implementation in e-commerce scenarios.Extract extensive data from various entities, such as content in e-commerce live broadcasts, products, merchants, and influencers. Model large-scale networks to support business scenarios like content understanding, multimodal representation, and community mining for problem-solving purposes.Participate in the construction of a large-scale graph storage and graph learning platform, supporting the basic ability of graph learning with billions of nodes and edges.QualificationsBachelor's degree or above in computer science or related fieldSolid coding skills, ability to develop in a Linux environment, proficient in Python, Go, or C++Solid foundation in data structures/algorithms, proficient in machine learning/deep learning theory, and rich practical experienceFamiliar with 1-2 areas in natural language processing, computer vision, multimodal, graph algorithms, search algorithms, text/data mining, and LLMExcellent analytical and problem-solving skills, passionate about challenging problemsGood team spirit and strong communication skillsExperience in platform governance/audit/risk control/content security or overseas internet/e-commerce business is preferredFluent English listening, speaking, reading, and writing skills are preferredExperience studying, working, or living overseas is preferred.TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 3ff66879-d68b-4cf7-9666-309432d8490c<br>**Similarity:** 0.318495937557449<br>**Text:** hot-path alerting with appropriate data storage strategies.Develop advanced correlation mechanisms to link model performance metrics with infrastructure telemetry.Create visualization layers that expose actionable insights rather than raw metrics.Implement anomaly detection systems that understand AI-specific failure modes.Domain-Specific Expertise:Design monitoring solutions for edge AI deployments addressing intermittent connectivity, battery usage, and on-device performance degradation.Create specialized observability patterns for generative AI systems including prompt tracking, token economics, and hallucination detection.Implement embeddings drift detection for NLP models and visual quality degradation tracking for computer vision systems.Design monitoring systems for reinforcement learning feedback loops and online learning environments.Develop systems to track model version lineage and A/B experiment outcomes.Integration & Operations:Implement advanced authentication and authorization patterns between observability componentsDesign network architecture that enables secure telemetry collection from air-gapped environmentsCreate backup and disaster recovery strategies specific to high-volume observability dataDevelop custom Kubernetes operators to automate observability infrastructure managementDesign and implement advanced alerting systems with noise reduction techniques and contextual notificationsRequired Qualifications:10+ years of software architecture experience with at least 3 years focused on AI platformsDeep expertise with Azure services including AKS, Container Apps, Event Hubs, Azure Monitor, Application Insights, and Azure Log AnalyticsHands-on experience implementing observability for at least two distinct AI domains (CV, NLP, GenAI, etc.)Demonstrated experience with high-scale telemetry ingestion (500+ events/second) and retention strategies.Practical experience integrating and extending third-party observability tools like Arize AI, Weights & Biases, or similar platformsExpertise in Kubernetes networking, custom resources, and operators relevant to observabilityStrong programming proficiency in at least two languages commonly used in observability (Python, Go, Java)Experience implementing distributed tracing solutions spanning multiple services and protocolsDemonstrated success designing intuitive dashboards that provide actionable insights from complex data.Preferred Qualifications:Experience implementing observability for models deployed across public cloud and edge devices simultaneouslyHands-on work with ML feature stores and feature monitoring in productionExperience developing custom Prometheus exporters or OpenTelemetry pluginsImplementation of explainability tracking for AI models in productionExperience with model governance and regulatory compliance monitoringKnowledge of dimensionality reduction techniques applied to observability data visualizationBackground designing systems that handle PII/sensitive data within observability platformsPractical experience with cost optimization for observability at scale (100+ TB of telemetry data)Technical Proficiencies:Kubernetes Ecosystem: Helm, Istio, Prometheus, Grafana, Jaeger, custom operators.Azure Platform: RBAC, Private Link, Managed Identities, KeyVault integration, AKS networking.Data Processing: Real-time stream processing, time-series databases, dimension reduction.API Design: RESTful API design, gRPC, GraphQL, API versioning strategies.AI Systems: Inference optimization, model drift detection, feature importance tracking.Security: Zero-trust architecture, secure telemetry collection, audit logging.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = retriever.retrieve(query)\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff9c4564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeWithScore(node=Document(id_='ac64db0a-86a4-4dfb-9f69-3827ae063e99', embedding=None, metadata={'id': '4208671629', 'title': 'Senior Deep Learning Engineer Intern - STWGB (April 2025 Start)', 'company': 'Flow', 'link': 'https://www.linkedin.com/jobs/view/4208671629/', 'keyword': 'Artificial Intelligence', 'location': 'Austin, TX'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Candidates should have hands-on experience with feature engineering pipelines that enhance the contextual accuracy of LLMs for long-sequence, multi-turn conversational modeling.Advanced experience with embedding manipulation techniques, such as masked token prediction, continuous token augmentation, and variational encoding, to dynamically adjust feature weights based on semantic proximity, particularly in dense retrieval tasks.Mastery of reinforcement learning paradigms for adaptive LLM fine-tuning, utilizing reward functions derived from similarity scores and relevance metrics in high-frequency retrieval systems to improve query-response fidelity.Complex Vector Database Integration & Feature Structuring for Semantic Similarity:Extensive experience designing and engineering feature vectors for semantic search optimization within vector databases (e.g., Pinecone, Faiss, Weaviate) and high-dimensional vector space management. Candidates should have technical proficiency in high-dimensional distance metrics such as cosine similarity, Euclidean distance, and inner product, optimized for specific retrieval tasks.Expert in structuring custom embeddings and vector schemas that enhance semantic search precision by capturing latent contextual signals through PCA, UMAP, and t-SNE techniques. Expertise in embedding normalization, vector scaling, and dimension reduction to balance retrieval speed and vector alignment accuracy.Ability to construct and manipulate KNN (k-nearest neighbor) indices, such as Hierarchical Navigable Small World (HNSW) graphs and IVF (Inverted File) structures, to optimize high-throughput search scenarios. Experience in designing vector clusters using k-means and density-based algorithms, enhancing semantic granularity across vectorized search spaces.High-Precision Semantic & Similarity Search EngineeringMastery in designing and implementing hybrid search architectures that combine dense embeddings with sparse vectors (BM25, TF-IDF) for enhanced retrieval relevance across semantic layers. Experience integrating hybrid dense-sparse models in RAG systems, ensuring that each query achieves optimal precision and recall based on adaptive similarity metrics.Expert in developing and tuning semantic similarity metrics, particularly cosine similarity, for real-time high-volume similarity search tasks. This includes leveraging cosine-similarity-based scoring mechanisms in similarity search pipelines to refine response ranking and ensure contextual relevance.Experience constructing cosine similarity feature transformations to boost search accuracy in query expansion contexts, utilizing cosine-based re-ranking and feature recalibration strategies that enable real-time refinement of relevance scoring.Specialized RAG-Specific Feature Engineering For Retrieval OptimizationExpertise in engineering feature pipelines within RAG architectures, specifically for enhancing query augmentation and retrieval conditioning based on multi-stage RAG frameworks. Candidates should have experience structuring bi-encoder and cross-encoder embeddings to support context-dependent token weighting and real-time relevance adjustments.Advanced experience in developing dynamic re-ranking mechanisms, integrating cosine and dot-product similarity metrics within RAG query layers for optimized retrieval at both coarse-grained and fine-grained levels. Expert in implementing memory-efficient vector stores and cached retrieval pathways that ensure low-latency response in high-frequency applications.Ability to optimize retrieval via custom feature weighting models, which selectively prioritize features based on semantic relevance derived from query intent prediction models, response context preservation, and adaptive relevance feedback mechanisms.Embedding & Similarity Feature Optimization With Real-Time SystemsExpert in designing high-dimensional embedding structures that support rapid cosine similarity calculations, especially within sparse or sparse-dense hybrid retrieval models. Familiarity with optimization techniques that reduce the computational load of similarity calculations in production-grade environments.Expertise in constructing advanced indexing schemes (e.g., IVF, PQ) that facilitate high-speed similarity search across large vector stores while minimizing precision loss. Skilled in implementing and tuning complex scoring layers, including custom cosine similarity scoring models that account for context-switching in multi-turn LLM interactions.Demonstrated capability in applying real-time re-ranking protocols within RAG-based systems, incorporating cosine-similarity-driven reordering, redundancy reduction in query results, and relevance fine-tuning based on LLM contextual embeddings.In addition to AI architecture and AI development, you will be responsible for engineering and implementingend-to-end AI pipelines, ensuring proper integration of these AI models into back-end systems developed usingDjango. You will be heavily involved in theintegration of AI with back-end systemsusingDjango, enabling flawless interactions between AI models and other system services. You will design, build, and manage APIs to support AI functionalities, ensuring efficient data exchange and smooth operations. ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=1.0085090012298172)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dae18b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_nodes = cohere_rerank.postprocess_nodes(nodes, query_bundle=QueryBundle(f\"what is best job for given resume {query}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "34ad4fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 54f713ab-35a5-4399-830a-a6fe346569c2<br>**Similarity:** 0.12863456<br>**Text:** The ideal candidate will be well-versed in the latest Large Language Model (LLM) technologies and have a strong background in data engineering, with a focus on Retrieval-Augmented Generation (RAG) and knowledge-base techniques.  This role sits in the AI COE within DX Tech & Digital. As a AI/LLM Data Engineer (you will report into the Director, AI Solutions & Development who oversees the AI COE.You will work on highly visible strategic projects, collaborating with cross-functional teamsto define requirements and deliver high-quality AI solutions.The ideal candidate will have a passion for Generative AI and LLMs, with a proven track record of delivering innovative AI applications.ResponsibilitiesDesign, implement, and maintain an end-to-end multi-stage data pipeline for LLMs, including Supervised Fine Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) data processesIdentify, evaluate, and integrate diverse data sources and domains to support the Generative AI platformDevelop and optimize data processing workflows for chunking, indexing, ingestion, and vectorization for both text and non-text dataBenchmark and implement various vector stores, embedding techniques, and retrieval methodsCreate a flexible pipeline supporting multiple embedding algorithms, vector stores, and search types (e.g., vector search, hybrid search)Implement and maintain auto-tagging systems and data preparation processes for LLMsDevelop tools for text and image data crawling, cleaning, and refinementCollaborate with cross-functional teams to ensure data quality and relevance for AI/ML modelsWork with data lake house architectures to optimize data storage and processingIntegrate and optimize workflows using Snowflake and various vector store technologiesRequirementsMaster's degree in Computer Science, Data Science, or a related field3-5 years of work experience in data engineering, preferably in AI/ML contextsProficiency in Python, JSON, HTTP, and related toolsStrong understanding of LLM architectures, training processes, and data requirementsExperience with RAG systems, knowledge base construction, and vector databasesFamiliarity with embedding techniques, similarity search algorithms, and information retrieval conceptsHands-on experience with data cleaning, tagging, and annotation processes (both manual and automated)Knowledge of data crawling techniques and associated ethical considerationsStrong problem-solving skills and ability to work in a fast-paced, innovative environmentFamiliarity with Snowflake and its integration in AI/ML pipelinesExperience with various vector store technologies and their applications in AIUnderstanding of data lakehouse concepts and architecturesExcellent communication, collaboration, and problem-solving skillsAbility to translate business needs into technical solutionsPassion for innovation and a commitment to ethical AI developmentExperience building LLMs pipeline using framework like LangChain, LlamaIndex, Semantic Kernel, OpenAI functionsFamiliar with different LLM parameters like temperate, top-k, and repeat penalty, and different LLM outcome evaluation data science metrics and methodologiesPreferred SkillsExperience with popular LLM/ RAG frameworksFamiliarity with distributed computing platforms (e.g., Apache Spark, Dask)Knowledge of data versioning and experiment tracking toolsExperience with cloud platforms (AWS, GCP, or Azure) for large-scale data processingUnderstanding of data privacy and security best practicesPractical experience implementing data lakehouse solutionsProficiency in optimizing queries and data processes in Snowflake or DatabricksHands-on experience with different vector store technologiesBenefitsUS employees benefit package<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** ac64db0a-86a4-4dfb-9f69-3827ae063e99<br>**Similarity:** 0.08137364<br>**Text:** Candidates should have hands-on experience with feature engineering pipelines that enhance the contextual accuracy of LLMs for long-sequence, multi-turn conversational modeling.Advanced experience with embedding manipulation techniques, such as masked token prediction, continuous token augmentation, and variational encoding, to dynamically adjust feature weights based on semantic proximity, particularly in dense retrieval tasks.Mastery of reinforcement learning paradigms for adaptive LLM fine-tuning, utilizing reward functions derived from similarity scores and relevance metrics in high-frequency retrieval systems to improve query-response fidelity.Complex Vector Database Integration & Feature Structuring for Semantic Similarity:Extensive experience designing and engineering feature vectors for semantic search optimization within vector databases (e.g., Pinecone, Faiss, Weaviate) and high-dimensional vector space management. Candidates should have technical proficiency in high-dimensional distance metrics such as cosine similarity, Euclidean distance, and inner product, optimized for specific retrieval tasks.Expert in structuring custom embeddings and vector schemas that enhance semantic search precision by capturing latent contextual signals through PCA, UMAP, and t-SNE techniques. Expertise in embedding normalization, vector scaling, and dimension reduction to balance retrieval speed and vector alignment accuracy.Ability to construct and manipulate KNN (k-nearest neighbor) indices, such as Hierarchical Navigable Small World (HNSW) graphs and IVF (Inverted File) structures, to optimize high-throughput search scenarios. Experience in designing vector clusters using k-means and density-based algorithms, enhancing semantic granularity across vectorized search spaces.High-Precision Semantic & Similarity Search EngineeringMastery in designing and implementing hybrid search architectures that combine dense embeddings with sparse vectors (BM25, TF-IDF) for enhanced retrieval relevance across semantic layers. Experience integrating hybrid dense-sparse models in RAG systems, ensuring that each query achieves optimal precision and recall based on adaptive similarity metrics.Expert in developing and tuning semantic similarity metrics, particularly cosine similarity, for real-time high-volume similarity search tasks. This includes leveraging cosine-similarity-based scoring mechanisms in similarity search pipelines to refine response ranking and ensure contextual relevance.Experience constructing cosine similarity feature transformations to boost search accuracy in query expansion contexts, utilizing cosine-based re-ranking and feature recalibration strategies that enable real-time refinement of relevance scoring.Specialized RAG-Specific Feature Engineering For Retrieval OptimizationExpertise in engineering feature pipelines within RAG architectures, specifically for enhancing query augmentation and retrieval conditioning based on multi-stage RAG frameworks. Candidates should have experience structuring bi-encoder and cross-encoder embeddings to support context-dependent token weighting and real-time relevance adjustments.Advanced experience in developing dynamic re-ranking mechanisms, integrating cosine and dot-product similarity metrics within RAG query layers for optimized retrieval at both coarse-grained and fine-grained levels. Expert in implementing memory-efficient vector stores and cached retrieval pathways that ensure low-latency response in high-frequency applications.Ability to optimize retrieval via custom feature weighting models, which selectively prioritize features based on semantic relevance derived from query intent prediction models, response context preservation, and adaptive relevance feedback mechanisms.Embedding & Similarity Feature Optimization With Real-Time SystemsExpert in designing high-dimensional embedding structures that support rapid cosine similarity calculations, especially within sparse or sparse-dense hybrid retrieval models. Familiarity with optimization techniques that reduce the computational load of similarity calculations in production-grade environments.Expertise in constructing advanced indexing schemes (e.g., IVF, PQ) that facilitate high-speed similarity search across large vector stores while minimizing precision loss. Skilled in implementing and tuning complex scoring layers, including custom cosine similarity scoring models that account for context-switching in multi-turn LLM interactions.Demonstrated capability in applying real-time re-ranking protocols within RAG-based systems, incorporating cosine-similarity-driven reordering, redundancy reduction in query results, and relevance fine-tuning based on LLM contextual embeddings.In addition to AI architecture and AI development, you will be responsible for engineering and implementingend-to-end AI pipelines, ensuring proper integration of these AI models into back-end systems developed usingDjango. You will be heavily i...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** d703c39b-a3fd-43de-a4df-80bad5bd9d43<br>**Similarity:** 0.05738754<br>**Text:** Your work will focus on enhancing user experiences by embedding natural language understanding into practical applications and improving real-time data processing.Key Responsibilities:Develop and optimize workflows for RAG and NLP models.Build and maintain scalable vector databases for AI applications.Design and implement applications that integrate with large language models via APIs, such as ChatGPT, for user interaction, query processing, and response generation.Collaborate with cross-functional teams to integrate AI capabilities into various systems.Conduct experiments to fine-tune models and enhance their performance.Stay updated on the latest trends and advancements in AI technologies.Required Qualifications:Bachelor’s degree in Computer Science, AI, or a related field.1-3 years of experience working with RAG, NLP, and vector databases.Proficiency in Python and experience with frameworks such as PyTorch, TensorFlow, or Hugging Face.Experience developing applications that interact with large language models.Familiarity with vector databases (e.g., Pinecone, Weaviate).Experience with real-time data retrieval and processing through APIs like ChatGPT.Strong understanding of natural language processing techniques and text embedding models.Desired Qualifications:Advanced degree in a relevant field.Experience deploying AI models in production environments.Familiarity with reinforcement learning for large language models and cloud platforms.Experience with frameworks like LangChain or Pydantic AI, or custom LLM frameworks.Experience with RAG applications, including locally hosted or public LLM API services.Experience with LLM tool calling and fine-tuning models for tasks like sentiment analysis and text classification.Expertise in language model prompt engineering.If you’re excited about building AI-driven applications and working with cutting-edge technologies, we’d love to hear from you!<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** e4506d74-8a55-4b01-aba0-6dcc5a608aff<br>**Similarity:** 0.0551069<br>**Text:** This role will involve working on various projects, including text analysis, language modeling, and model deployment in production environments. You will also be instrumental in applying generative models for creative and business purposes, such as text generation and data augmentation.Primary Responsibilities/Essential FunctionsNatural Language Processing (NLP):Lead the design and implementation of advanced NLP models for tasks such as text classification, named entity recognition (NER), topic modeling, sentiment analysis, and language translation.Apply cutting-edge deep learning techniques like Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTMs), and transformer models (e.g., BERT, GPT) for complex NLP tasks.Leverage pre-trained language models, word embeddings (Word2Vec, GloVe, FastText), and fine-tune them to meet custom business requirements.Generative AI:Apply Generative AI techniques, such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformer-based models (e.g., GPT-3, T5), to develop solutions for text generation, data augmentation, and other creative use cases.Explore innovative applications of Generative AI in content creation, including summarization, question generation, and dialogue systems.Stay up-to-date with the latest advancements in Generative AI, and integrate them into existing pipelines to enhance model performance and functionality.Collaborate with cross-functional teams to explore new business applications for generative models, such as synthetic data generation for model training or content generation for marketing.Supervised Learning:Develop and optimize machine learning models using supervised learning techniques such as regression, classification, Support Vector Machines (SVMs), and decision trees.Evaluate models using performance metrics such as accuracy, precision, recall, F1 score, and use cross-validation to ensure model robustness.Unsupervised Learning:Use clustering algorithms, such as K-means and hierarchical clustering, and dimensionality reduction techniques like Principal Component Analysis (PCA) to uncover hidden patterns in data.Implement anomaly detection models to identify rare events or outliers in datasets, supporting business intelligence and decision-making.Deep Learning:Lead the design and deployment of deep learning models using Convolutional Neural Networks (CNNs), RNNs, LSTMs, and transformers to handle complex tasks in both NLP and Generative AI.Optimize and fine-tune deep learning architectures to improve accuracy, performance, and scalability of models in production.Model Deployment and MLOps:Deploy machine learning models into production using cloud platforms such as Azure ML, ensuring scalability and performance.Implement MLOps best practices, including CI/CD pipelines, model versioning, and automated retraining using tools like MLflow, Kubeflow, and Azure ML Pipelines.Monitor models post-deployment, track model performance, identify drift, and retrain models as necessary to maintain their relevance and accuracy.QualificationsEducation:Master’s or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering, or a related field.Experience:5+ years of experience in machine learning, with a focus on Natural Language Processing (NLP) and Generative AI.Extensive experience with deep learning frameworks such as TensorFlow, Keras, or PyTorch for building and deploying models.Proven expertise in deploying models to production environments using cloud platforms such as Azure ML, AWS, or GCP.Familiarity with MLOps practices, including CI/CD, model versioning, and automated retraining.Technical Skills:Proficiency in Python and machine learning libraries such as scikit-learn, TensorFlow, PyTorch, Keras, Hugging Face Transformers, NLTK, and SpaCy.Expertise in NLP techniques, including tokenization, word embeddings, transformers (e.g., BERT, GPT), and sequence models like RNNs and LSTMs.Experience with Generative AI models such as GANs, VAEs, and transformers (e.g., GPT-3, T5) for tasks like text generation and data augmentation.Experience with cloud platforms for model deployment, including Azure ML, AWS, or GCP.Familiarity with MLOps tools such as MLflow, Kubeflow, and Azure ML Pipelines for tracking, monitoring, and automating ML models.Leadership and Soft Skills:Excellent communication skills with the ability to explain complex technical concepts to non-technical stakeholders.Collaborate with data engineers, product managers, and other stakeholders to translate business requirements into machine learning solutions.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** d15af210-bf4e-42c8-beb6-61f0e134026c<br>**Similarity:** 0.05005131<br>**Text:** This position is ideal for individuals seeking a career in senior AI engineering and interested in working with a pioneering company in enterprise AI solutions.In this position, you will engage heavily in the development ofnatural language processing (NLP)models,large language models (LLMs)likeRAG,DistilBERT,BERT,RoBERTa, andLLaMA, as well asdeep reinforcement learningtechniques to create AI systems that learn, adapt, and evolve. You will be directly responsible for building AI pipelines, refining training methodologies, and implementing real-time solutions, ensuring they are secure, reliable, and optimized for performance in live cloud environments. In this role, you will be at the forefront of Flow's R&D initiatives, engaging in the entire AI development lifecycle. You’ll design, implement, and refine AI and deep learning models using state-of-the-art frameworks such asTensorFlow,PyTorch, and Keras, with a focus on Natural Language Processing (NLP), Large Language Models (LLMs) includingRAG, BERT, DistilBERT, RoBERTa, and LLaMA, and advanced neural architectures dedicated to Flow’s SaaS AI sales solutions. You’ll leverage these models in a cloud-based infrastructure, ensuring they are optimized, scalable, and capable of handling high-availability production loads.LLM-Specific Feature Optimization For Enhanced Contextual RelevanceCandidates must demonstrate extensive previous experience inadvanced feature engineeringfor optimizing large language models (LLMs) and Retrieval-Augmented Generation (RAG) architectures, specifically within high-dimensional vectorized environments. Expertise should encompass the following technical capabilities:Expert in engineering token embeddings, positional encodings, and contextual attention mechanisms tailored to transformer-based architectures (GPT, T5, BERT) within RAG frameworks.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 849337b7-1136-4d28-87d4-ca5c3bb90884<br>**Similarity:** 0.04822634<br>**Text:** Working collaboratively, we advance missions and careers through a focus on honesty, integrity, and dependability. We continuously look for talent, excited to join that effort. To learn more about our exciting organization, please visit us at www.unissant.com.We are seeking anAI-ML Developerto join our team and support our Department of Homeland Security (DHS) customer in theWashington DCmetro area.Essential Duties And ResponsibilitiesAs the AI/ML developer, an ideal candidate will be part of a team to provide consultative, architectural, program, and engineering support for a federal customerDrive a big data approach to execute government requirements to manage and enrich data to gather new insights.Develop, train, and deploy advanced AI/ML models, including generative AI techniques like large language models (LLMs).Design and implement innovative AI solutions to address complex business challenges, such as natural language processing.Optimize model performance, ensuring accuracy, efficiency, and scalability.Develop, train, deploy and maintain user-friendly AI applications and interfaces, including chatbots, virtual assistants, and generative content tools.Collaborate with cross-functional teams to integrate AI solutions into existing systems and workflows.Stay up to date with the latest advancements in AI/ML and emerging technologies, such as generative AI and reinforcement learning.Conduct research and experiments to explore new AI techniques and applications, including prompt engineering, Advanced RAGs and fine-tuning LLMs.Ensure compliance with data privacy and security regulations, especially when dealing with sensitive data and generative AI outputs.Responsible for briefing the benefits and constraints of technology solutions to technology partners, stakeholders, team members, and senior levels of managementWork Experience5+ years of experience in the Information Technology field focusing on AI/ML engineering projects, MLOps/DevSecOps and technical architecture specifically.Experience in architecture & design, with a preference for 3 years of experience deploying production enterprise applications on-prem or on cloud.Experience with classification, forecasting, transformers, and generative models.Experience in data visualization using tools like Plotly and Matplotlib.Experience in large-scale, high-performance enterprise big data application deployment and solution architecture on complex heterogeneous environment.Experience with machine learning and generative AI frameworks.Experience with natural language processing techniques (e.g., text classification, language generation).Solid understanding of any of the cloud platforms (e.g., AWS, Azure, GCP) and deployment strategies.Job SkillsDatabase Knowledge: Knowledge of database systems (e.g., SQL, NoSQL) and data warehousing concepts.Generative AI Models: Proficiency in developing, deploying, and fine-tuning generative AI models, including large language models (LLMs).Multi-Agent / Agentic-AI Models: Proficiency in building Agentic-AI systems using tools such as LangChain Agents and Crew-AI.Cloud AI-ML Resource Knowledge: Knowledge of AWS SageMaker, Bedrock, Amazon Q, Amazon Elastic Inference.Programming Languages: Strong proficiency in programming languages such as Python, R, Java, and C/C++.Front-end Development: Proficiency in any front-end development technologies (e.g., React, Angular, Vue.js, HTML, CSS, JavaScript).Data Analytics: Expertise with libraries such as Pandas and NumPy for data manipulation and exploration.ML Frameworks: Proficiency in ML Modeling concepts and frameworks like Scikit-Learn, TensorFlow, Keras, PyTorch, and others.Data Preprocessing: Strong skills in data encoding, normalizing, and regularizing to prepare datasets for ML models.Deep Learning: Solid understanding of deep learning architectures such as CNNs (Convolutional Neural Networks), RNNs (Recurrent Neural Networks), LSTMs (Long Short-Term Memory networks), and GANs (Generative Adversarial Networks), with the ability to apply them to real-world data sets and problems.Anomaly Detection: Familiarity with anomaly detection techniques and deep learning models.Cloud Platforms: Solid understanding of cloud services, such as AWS, Azure, or GCP, and deployment strategies.EducationBachelor's degree in computer science, Information Technology Management or Engineering is preferred. Alternative work-related experience, Military Duty, and/or specialized or higher education may be substituted.Certificates, Licenses And RegistrationsThis federal program requires the candidates to be a United States Citizen.DHS Public Trust and/or DOD TS clearance is preferred.Qualified applicants may be subject to a security investigation and must meet minimum qualifications for access to classified information.Any related systems engineering, or related technical certifications are desired.AWS/Azure/GCP AI/ML certifications are preferred but not required.Communication SkillsExcellent verbal and...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 5d86fa6f-2598-418f-aad7-7e7a56046f4c<br>**Similarity:** 0.02870708<br>**Text:** ACTIVE TS/SCI SECURITY CLEARANCE AND POLYGRAPH REQUIRED**Position Overview:D2 Consulting is seeking a highly skilledAI/LLM Engineerwith an activeTS/SCI clearance and CI polygraphto lead the design, deployment, and optimization of an on-premises Large Language Model (LLM) solution. This role involves architecting and implementing secure, scalable AI systems capable of ingesting, processing, and analyzing large datasets — including structured and unstructured data comprisingmillions of records.You will work alongside cross-functional teams supporting critical missions within the Intelligence Community, applying cutting-edge AI/ML techniques to drive insights and decision-making in secure environments.Key Responsibilities:Design and implement secure, on-premises LLM infrastructure and pipelines tailored to mission needsEvaluate, fine-tune, and deploy open-source or custom LLMs within air-gapped environmentsDevelop and manage data pipelines for ingesting and processing structured and unstructured datasets at scaleApply NLP, ML, and data science techniques to extract insights from massive datasets (millions+ records)Collaborate with analysts, engineers, and mission stakeholders to shape AI capabilities around operational requirementsEnsure compliance with security and data governance standards for classified environmentsMonitor model performance, implement updates, and optimize compute usageBasic Qualifications:Active TS/SCI clearance with CI Polygraph5+ years of experience in AI/ML engineering, data science, or software developmentHands-on experience deploying or fine-tuning LLMs (e.g., LLaMA, Mistral, GPT-NeoX, BERT, etc.)Experience with on-prem or air-gapped AI/ML deployments, including containerized or GPU-based environmentsStrong proficiency in Python and common ML/NLP libraries (e.g., Hugging Face Transformers, PyTorch, LangChain)Experience working with large datasets (millions of records), including ETL and data transformation pipelinesSolid understanding of system architecture, data privacy, and secure computing practicesPreferred Qualifications:Experience deploying quantized models for performance optimization (e.g., using llama.cpp, ggml, gguf)Familiarity with GPU server infrastructure (e.g., NVIDIA A100/RTX, CUDA) or multi-node compute setupsKnowledge of cloud-to-on-prem transition architecturesBackground in supporting Intelligence Community or DoD missionsWhy Join D2 Consulting?As aVeteran-Owned Small Business, D2 Consulting delivers enterprise IT services to the U.S.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 1f346c87-d9e2-4875-bd31-3e62a3642b74<br>**Similarity:** 0.02727267<br>**Text:** Courage? Always.At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.Join us.About The TeamThe Governance and Experience Algorithm team was established in September 2020 and its main job is to support the following businesses with the most advanced AI technology：Combat any kinds of risks/violations issues in E-commerce scenarios.Build an E-commerce ecosystem and improve platform service capabilitiesResponsibilities:Responsible for identifying algorithms for risk/violation/low-quality issues in e-commerce scenarios such as products, shopping cart short videos, and live streaming with products.Responsible for mining and identifying algorithms to detect fraudulent behaviors and identify risky, violated, or low-quality merchants and creators.Responsible for optimizing algorithms for large-scale brand libraries, products, and content deduplication/clustering.Responsible for data construction, instruction fine-tuning, CoT, alignment, and other work for large models in the e-commerce domain, aiming for ultimate effect optimization in the e-commerce domain.Responsible for exploring reinforcement learning and operational research algorithms in intelligent dispatching and intelligent audit scheduling to improve audit quality and efficiency.What You Will Do:Optimize various basic algorithms such as NLP, vision, multimodal, search, graph, LLM, etc. to provide support for governance business, explore cutting-edge technologies, and apply them to e-commerce business scenarios.Streamline the optimization and iteration process for computer vision models in e-commerce settings, including fine-grained classification of product images, product object recognition, product subject recognition, feature extraction, logo detection, brand recognition, etc.Optimize video classification, multimodal content mining, and multimodal content understanding of e-commerce short videos and live broadcasts, and optimize the e-commerce short video shopping experience.Optimize the risk identification model related to text content in e-commerce scenarios, such as product copywriting, picture text, and voice descriptions.Optimize the risk mining algorithm for comments, reports, and other public opinion content related to products/short videos/live broadcasts, and improve the platform governance effect.Responsible for the research of large-scale multimodal (vision, speech, natural language, etc.) algorithms and their implementation in e-commerce scenarios.Extract extensive data from various entities, such as content in e-commerce live broadcasts, products, merchants, and influencers. Model large-scale networks to support business scenarios like content understanding, multimodal representation, and community mining for problem-solving purposes.Participate in the construction of a large-scale graph storage and graph learning platform, supporting the basic ability of graph learning with billions of nodes and edges.QualificationsBachelor's degree or above in computer science or related fieldSolid coding skills, ability to develop in a Linux environment, proficient in Python, Go, or C++Solid foundation in data structures/algorithms, proficient in machine learning/deep learning theory, and rich practical experienceFamiliar with 1-2 areas in natural language processing, computer vision, multimodal, graph algorithms, search algorithms, text/data mining, and LLMExcellent analytical and problem-solving skills, passionate about challenging problemsGood team spirit and strong communication skillsExperience in platform governance/audit/risk control/content security or overseas internet/e-commerce business is preferredFluent English listening, speaking, reading, and writing skills are preferredExperience studying, working, or living overseas is preferred.TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 3ff66879-d68b-4cf7-9666-309432d8490c<br>**Similarity:** 0.022074386<br>**Text:** hot-path alerting with appropriate data storage strategies.Develop advanced correlation mechanisms to link model performance metrics with infrastructure telemetry.Create visualization layers that expose actionable insights rather than raw metrics.Implement anomaly detection systems that understand AI-specific failure modes.Domain-Specific Expertise:Design monitoring solutions for edge AI deployments addressing intermittent connectivity, battery usage, and on-device performance degradation.Create specialized observability patterns for generative AI systems including prompt tracking, token economics, and hallucination detection.Implement embeddings drift detection for NLP models and visual quality degradation tracking for computer vision systems.Design monitoring systems for reinforcement learning feedback loops and online learning environments.Develop systems to track model version lineage and A/B experiment outcomes.Integration & Operations:Implement advanced authentication and authorization patterns between observability componentsDesign network architecture that enables secure telemetry collection from air-gapped environmentsCreate backup and disaster recovery strategies specific to high-volume observability dataDevelop custom Kubernetes operators to automate observability infrastructure managementDesign and implement advanced alerting systems with noise reduction techniques and contextual notificationsRequired Qualifications:10+ years of software architecture experience with at least 3 years focused on AI platformsDeep expertise with Azure services including AKS, Container Apps, Event Hubs, Azure Monitor, Application Insights, and Azure Log AnalyticsHands-on experience implementing observability for at least two distinct AI domains (CV, NLP, GenAI, etc.)Demonstrated experience with high-scale telemetry ingestion (500+ events/second) and retention strategies.Practical experience integrating and extending third-party observability tools like Arize AI, Weights & Biases, or similar platformsExpertise in Kubernetes networking, custom resources, and operators relevant to observabilityStrong programming proficiency in at least two languages commonly used in observability (Python, Go, Java)Experience implementing distributed tracing solutions spanning multiple services and protocolsDemonstrated success designing intuitive dashboards that provide actionable insights from complex data.Preferred Qualifications:Experience implementing observability for models deployed across public cloud and edge devices simultaneouslyHands-on work with ML feature stores and feature monitoring in productionExperience developing custom Prometheus exporters or OpenTelemetry pluginsImplementation of explainability tracking for AI models in productionExperience with model governance and regulatory compliance monitoringKnowledge of dimensionality reduction techniques applied to observability data visualizationBackground designing systems that handle PII/sensitive data within observability platformsPractical experience with cost optimization for observability at scale (100+ TB of telemetry data)Technical Proficiencies:Kubernetes Ecosystem: Helm, Istio, Prometheus, Grafana, Jaeger, custom operators.Azure Platform: RBAC, Private Link, Managed Identities, KeyVault integration, AKS networking.Data Processing: Real-time stream processing, time-series databases, dimension reduction.API Design: RESTful API design, gRPC, GraphQL, API versioning strategies.AI Systems: Inference optimization, model drift detection, feature importance tracking.Security: Zero-trust architecture, secure telemetry collection, audit logging.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 3c9109f0-a4fc-4f61-a3a2-2aecd7e261c6<br>**Similarity:** 0.018689308<br>**Text:** TensorFlow Lite) is a plusExperience building ML models with time-series or sequential data (such as NLP), especially for long time sequences and real-time processing scenarios. Experience working with sensor data is a plusFamiliarity with reinforcement learning (RL), computational graphs, and/or graph neural networks is a plus.Knowledgeable in techniques to optimize ML models for inference in compute-limited scenarios (i.e. model distillation, pruning, dimensionality reduction, feature selection, parallelization)Familiar deploying models for fast, efficient inference on compute accelerators (TPUs or NPUs).Proficient in designing, implementing, and maintaining robust ML pipelines for end-to-end model lifecycle management. Experience benchmarking multiple models is a plus.Familiar deploying models in containerized settings, such as Docker. Knowledge of Kubernetes and/or Docker Swarm is a plus. Familiar with SQL or similar database systems (such as MySQL, PostgreSQL, MongoDB)Proficient in Git or other version control systemsFamiliar with cloud platforms such as AWS, Azure, or Google CloudExperience working with LLMs/RAG is a plus, especially in building a company knowledgebase, chatbot, or for data analysis/summarization. Familiarity with Agile methodologies and experience in collaborative, cross-functional teamsAnalytical thinker with the ability to solve complex problems efficientlyExcellent communication skills to articulate technical issues, solutions, and progress effectivelyAdaptability to learn new technologies and adapt to evolving project requirementsStrong team player mindset, comfortable sharing knowledge and collaborating within a team environmentFamiliarity with Agile methodologies and experience in collaborative, cross-functional teamsAnalytical thinker with the ability to solve complex problems efficientlyMeticulous attention to detail in writing clean, maintainable code and designing robust database architecturesExcellent communication skills to articulate technical issues, solutions, and progress effectivelyAdaptability to learn new technologies and adapt to evolving project requirementsBenefitsDirect impact on product and cultureComprehensive benefits package including Medical, Dental, Vision, Life Insurance, Disability, Transportation benefit, Health and Wellness benefit, and more401k plan with employer matchingEquityCompetitive salary and bonus opportunitiesDynamic and inclusive work environmentOpportunities for growth and professional developmentAccess to Greentown Labs' extensive network of cleantech startupsLearn How We ThinkLearn about our startup journey: Our JourneyHow we're combating climate change: AI-Powered Climate TechA customer story: Ben & Jerry's uses H2Ok's precision automation to cut time & water usageWhy H2Ok Innovations?Impact:Work on cutting-edge AI and sensor tech that’s already transforming how factories use water, energy, and chemicals. Join a tight-knit, ambitious team where your contributions can reshape the industry.Growth:Join a fast-growing startup where you’ll have the opportunity to shape our content strategy. We value fostering extraordinary growth in our teammates.Innovative Culture:Work in a high-performance environment that values empowerment, creativity, ownership, autonomy, innovation, excellence, passion, and continuous growth.Sustainability Focus:Play a key role in promoting sustainability and Industry 4.0 advancements in manufacturing.Build the intelligence layer powering the next generation of industrial efficiency – with a team that moves fast and delivers real impact.At H2Ok Innovations, we’re committed to diversity, equity, and inclusion, and we encourage applicants from all backgrounds to apply.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rerank_nodes\n",
    "for node in rerank_nodes:\n",
    "    display_source_node(node, source_length=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23f0e0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='ac64db0a-86a4-4dfb-9f69-3827ae063e99', embedding=None, metadata={'id': '4208671629', 'title': 'Senior Deep Learning Engineer Intern - STWGB (April 2025 Start)', 'company': 'Flow', 'link': 'https://www.linkedin.com/jobs/view/4208671629/', 'keyword': 'Artificial Intelligence', 'location': 'Austin, TX'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Candidates should have hands-on experience with feature engineering pipelines that enhance the contextual accuracy of LLMs for long-sequence, multi-turn conversational modeling.Advanced experience with embedding manipulation techniques, such as masked token prediction, continuous token augmentation, and variational encoding, to dynamically adjust feature weights based on semantic proximity, particularly in dense retrieval tasks.Mastery of reinforcement learning paradigms for adaptive LLM fine-tuning, utilizing reward functions derived from similarity scores and relevance metrics in high-frequency retrieval systems to improve query-response fidelity.Complex Vector Database Integration & Feature Structuring for Semantic Similarity:Extensive experience designing and engineering feature vectors for semantic search optimization within vector databases (e.g., Pinecone, Faiss, Weaviate) and high-dimensional vector space management. Candidates should have technical proficiency in high-dimensional distance metrics such as cosine similarity, Euclidean distance, and inner product, optimized for specific retrieval tasks.Expert in structuring custom embeddings and vector schemas that enhance semantic search precision by capturing latent contextual signals through PCA, UMAP, and t-SNE techniques. Expertise in embedding normalization, vector scaling, and dimension reduction to balance retrieval speed and vector alignment accuracy.Ability to construct and manipulate KNN (k-nearest neighbor) indices, such as Hierarchical Navigable Small World (HNSW) graphs and IVF (Inverted File) structures, to optimize high-throughput search scenarios. Experience in designing vector clusters using k-means and density-based algorithms, enhancing semantic granularity across vectorized search spaces.High-Precision Semantic & Similarity Search EngineeringMastery in designing and implementing hybrid search architectures that combine dense embeddings with sparse vectors (BM25, TF-IDF) for enhanced retrieval relevance across semantic layers. Experience integrating hybrid dense-sparse models in RAG systems, ensuring that each query achieves optimal precision and recall based on adaptive similarity metrics.Expert in developing and tuning semantic similarity metrics, particularly cosine similarity, for real-time high-volume similarity search tasks. This includes leveraging cosine-similarity-based scoring mechanisms in similarity search pipelines to refine response ranking and ensure contextual relevance.Experience constructing cosine similarity feature transformations to boost search accuracy in query expansion contexts, utilizing cosine-based re-ranking and feature recalibration strategies that enable real-time refinement of relevance scoring.Specialized RAG-Specific Feature Engineering For Retrieval OptimizationExpertise in engineering feature pipelines within RAG architectures, specifically for enhancing query augmentation and retrieval conditioning based on multi-stage RAG frameworks. Candidates should have experience structuring bi-encoder and cross-encoder embeddings to support context-dependent token weighting and real-time relevance adjustments.Advanced experience in developing dynamic re-ranking mechanisms, integrating cosine and dot-product similarity metrics within RAG query layers for optimized retrieval at both coarse-grained and fine-grained levels. Expert in implementing memory-efficient vector stores and cached retrieval pathways that ensure low-latency response in high-frequency applications.Ability to optimize retrieval via custom feature weighting models, which selectively prioritize features based on semantic relevance derived from query intent prediction models, response context preservation, and adaptive relevance feedback mechanisms.Embedding & Similarity Feature Optimization With Real-Time SystemsExpert in designing high-dimensional embedding structures that support rapid cosine similarity calculations, especially within sparse or sparse-dense hybrid retrieval models. Familiarity with optimization techniques that reduce the computational load of similarity calculations in production-grade environments.Expertise in constructing advanced indexing schemes (e.g., IVF, PQ) that facilitate high-speed similarity search across large vector stores while minimizing precision loss. Skilled in implementing and tuning complex scoring layers, including custom cosine similarity scoring models that account for context-switching in multi-turn LLM interactions.Demonstrated capability in applying real-time re-ranking protocols within RAG-based systems, incorporating cosine-similarity-driven reordering, redundancy reduction in query results, and relevance fine-tuning based on LLM contextual embeddings.In addition to AI architecture and AI development, you will be responsible for engineering and implementingend-to-end AI pipelines, ensuring proper integration of these AI models into back-end systems developed usingDjango. You will be heavily involved in theintegration of AI with back-end systemsusingDjango, enabling flawless interactions between AI models and other system services. You will design, build, and manage APIs to support AI functionalities, ensuring efficient data exchange and smooth operations. ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.03333333333333333),\n",
       " NodeWithScore(node=TextNode(id_='e4506d74-8a55-4b01-aba0-6dcc5a608aff', embedding=None, metadata={'id': '4160259559', 'title': 'Senior Machine Learning Engineer/Data Scientist (NLP)', 'company': 'ReturnPro', 'link': 'https://www.linkedin.com/jobs/view/4160259559/', 'keyword': 'MLOps', 'location': 'Miami, FL'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='This role will involve working on various projects, including text analysis, language modeling, and model deployment in production environments. You will also be instrumental in applying generative models for creative and business purposes, such as text generation and data augmentation.Primary Responsibilities/Essential FunctionsNatural Language Processing (NLP):Lead the design and implementation of advanced NLP models for tasks such as text classification, named entity recognition (NER), topic modeling, sentiment analysis, and language translation.Apply cutting-edge deep learning techniques like Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTMs), and transformer models (e.g., BERT, GPT) for complex NLP tasks.Leverage pre-trained language models, word embeddings (Word2Vec, GloVe, FastText), and fine-tune them to meet custom business requirements.Generative AI:Apply Generative AI techniques, such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformer-based models (e.g., GPT-3, T5), to develop solutions for text generation, data augmentation, and other creative use cases.Explore innovative applications of Generative AI in content creation, including summarization, question generation, and dialogue systems.Stay up-to-date with the latest advancements in Generative AI, and integrate them into existing pipelines to enhance model performance and functionality.Collaborate with cross-functional teams to explore new business applications for generative models, such as synthetic data generation for model training or content generation for marketing.Supervised Learning:Develop and optimize machine learning models using supervised learning techniques such as regression, classification, Support Vector Machines (SVMs), and decision trees.Evaluate models using performance metrics such as accuracy, precision, recall, F1 score, and use cross-validation to ensure model robustness.Unsupervised Learning:Use clustering algorithms, such as K-means and hierarchical clustering, and dimensionality reduction techniques like Principal Component Analysis (PCA) to uncover hidden patterns in data.Implement anomaly detection models to identify rare events or outliers in datasets, supporting business intelligence and decision-making.Deep Learning:Lead the design and deployment of deep learning models using Convolutional Neural Networks (CNNs), RNNs, LSTMs, and transformers to handle complex tasks in both NLP and Generative AI.Optimize and fine-tune deep learning architectures to improve accuracy, performance, and scalability of models in production.Model Deployment and MLOps:Deploy machine learning models into production using cloud platforms such as Azure ML, ensuring scalability and performance.Implement MLOps best practices, including CI/CD pipelines, model versioning, and automated retraining using tools like MLflow, Kubeflow, and Azure ML Pipelines.Monitor models post-deployment, track model performance, identify drift, and retrain models as necessary to maintain their relevance and accuracy.QualificationsEducation:Master’s or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering, or a related field.Experience:5+ years of experience in machine learning, with a focus on Natural Language Processing (NLP) and Generative AI.Extensive experience with deep learning frameworks such as TensorFlow, Keras, or PyTorch for building and deploying models.Proven expertise in deploying models to production environments using cloud platforms such as Azure ML, AWS, or GCP.Familiarity with MLOps practices, including CI/CD, model versioning, and automated retraining.Technical Skills:Proficiency in Python and machine learning libraries such as scikit-learn, TensorFlow, PyTorch, Keras, Hugging Face Transformers, NLTK, and SpaCy.Expertise in NLP techniques, including tokenization, word embeddings, transformers (e.g., BERT, GPT), and sequence models like RNNs and LSTMs.Experience with Generative AI models such as GANs, VAEs, and transformers (e.g., GPT-3, T5) for tasks like text generation and data augmentation.Experience with cloud platforms for model deployment, including Azure ML, AWS, or GCP.Familiarity with MLOps tools such as MLflow, Kubeflow, and Azure ML Pipelines for tracking, monitoring, and automating ML models.Leadership and Soft Skills:Excellent communication skills with the ability to explain complex technical concepts to non-technical stakeholders.Collaborate with data engineers, product managers, and other stakeholders to translate business requirements into machine learning solutions.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.032266458495966696),\n",
       " NodeWithScore(node=TextNode(id_='d703c39b-a3fd-43de-a4df-80bad5bd9d43', embedding=None, metadata={'id': '4202593172', 'title': 'AI Application Engineer', 'company': 'Stelvio Group', 'link': 'https://www.linkedin.com/jobs/view/4202593172/', 'keyword': 'LLM Engineer', 'location': 'Denver, CO'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Your work will focus on enhancing user experiences by embedding natural language understanding into practical applications and improving real-time data processing.Key Responsibilities:Develop and optimize workflows for RAG and NLP models.Build and maintain scalable vector databases for AI applications.Design and implement applications that integrate with large language models via APIs, such as ChatGPT, for user interaction, query processing, and response generation.Collaborate with cross-functional teams to integrate AI capabilities into various systems.Conduct experiments to fine-tune models and enhance their performance.Stay updated on the latest trends and advancements in AI technologies.Required Qualifications:Bachelor’s degree in Computer Science, AI, or a related field.1-3 years of experience working with RAG, NLP, and vector databases.Proficiency in Python and experience with frameworks such as PyTorch, TensorFlow, or Hugging Face.Experience developing applications that interact with large language models.Familiarity with vector databases (e.g., Pinecone, Weaviate).Experience with real-time data retrieval and processing through APIs like ChatGPT.Strong understanding of natural language processing techniques and text embedding models.Desired Qualifications:Advanced degree in a relevant field.Experience deploying AI models in production environments.Familiarity with reinforcement learning for large language models and cloud platforms.Experience with frameworks like LangChain or Pydantic AI, or custom LLM frameworks.Experience with RAG applications, including locally hosted or public LLM API services.Experience with LLM tool calling and fine-tuning models for tasks like sentiment analysis and text classification.Expertise in language model prompt engineering.If you’re excited about building AI-driven applications and working with cutting-edge technologies, we’d love to hear from you!', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.03128054740957967),\n",
       " NodeWithScore(node=TextNode(id_='54f713ab-35a5-4399-830a-a6fe346569c2', embedding=None, metadata={'id': '4068838711', 'title': 'LLM Data Engineer | United States | Fully Remote', 'company': 'Halo Media', 'link': 'https://www.linkedin.com/jobs/view/4068838711/', 'keyword': 'LLM Engineer', 'location': 'Tallahassee, FL'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"The ideal candidate will be well-versed in the latest Large Language Model (LLM) technologies and have a strong background in data engineering, with a focus on Retrieval-Augmented Generation (RAG) and knowledge-base techniques.\\u202f This role sits in the AI COE within DX Tech & Digital. As a AI/LLM Data Engineer (you will report into the Director, AI Solutions & Development who oversees the AI COE.You will work on highly visible strategic projects, collaborating with cross-functional teamsto define requirements and deliver high-quality AI solutions.The ideal candidate will have a passion for Generative AI and LLMs, with a proven track record of delivering innovative AI applications.ResponsibilitiesDesign, implement, and maintain an end-to-end multi-stage data pipeline for LLMs, including Supervised Fine Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) data processesIdentify, evaluate, and integrate diverse data sources and domains to support the Generative AI platformDevelop and optimize data processing workflows for chunking, indexing, ingestion, and vectorization for both text and non-text dataBenchmark and implement various vector stores, embedding techniques, and retrieval methodsCreate a flexible pipeline supporting multiple embedding algorithms, vector stores, and search types (e.g., vector search, hybrid search)Implement and maintain auto-tagging systems and data preparation processes for LLMsDevelop tools for text and image data crawling, cleaning, and refinementCollaborate with cross-functional teams to ensure data quality and relevance for AI/ML modelsWork with data lake house architectures to optimize data storage and processingIntegrate and optimize workflows using Snowflake and various vector store technologiesRequirementsMaster's degree in Computer Science, Data Science, or a related field3-5 years of work experience in data engineering, preferably in AI/ML contextsProficiency in Python, JSON, HTTP, and related toolsStrong understanding of LLM architectures, training processes, and data requirementsExperience with RAG systems, knowledge base construction, and vector databasesFamiliarity with embedding techniques, similarity search algorithms, and information retrieval conceptsHands-on experience with data cleaning, tagging, and annotation processes (both manual and automated)Knowledge of data crawling techniques and associated ethical considerationsStrong problem-solving skills and ability to work in a fast-paced, innovative environmentFamiliarity with Snowflake and its integration in AI/ML pipelinesExperience with various vector store technologies and their applications in AIUnderstanding of data lakehouse concepts and architecturesExcellent communication, collaboration, and problem-solving skillsAbility to translate business needs into technical solutionsPassion for innovation and a commitment to ethical AI developmentExperience building LLMs pipeline using framework like LangChain, LlamaIndex, Semantic Kernel, OpenAI functionsFamiliar with different LLM parameters like temperate, top-k, and repeat penalty, and different LLM outcome evaluation data science metrics and methodologiesPreferred SkillsExperience with popular LLM/ RAG frameworksFamiliarity with distributed computing platforms (e.g., Apache Spark, Dask)Knowledge of data versioning and experiment tracking toolsExperience with cloud platforms (AWS, GCP, or Azure) for large-scale data processingUnderstanding of data privacy and security best practicesPractical experience implementing data lakehouse solutionsProficiency in optimizing queries and data processes in Snowflake or DatabricksHands-on experience with different vector store technologiesBenefitsUS employees benefit package\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.03125763125763126),\n",
       " NodeWithScore(node=TextNode(id_='849337b7-1136-4d28-87d4-ca5c3bb90884', embedding=None, metadata={'id': '4191012502', 'title': 'AI ML Developer', 'company': 'Unissant', 'link': 'https://www.linkedin.com/jobs/view/4191012502/', 'keyword': 'MLOps', 'location': 'Ashburn, VA'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"Working collaboratively, we advance missions and careers through a focus on honesty, integrity, and dependability. We continuously look for talent, excited to join that effort. To learn more about our exciting organization, please visit us at www.unissant.com.We are seeking anAI-ML Developerto join our team and support our Department of Homeland Security (DHS) customer in theWashington DCmetro area.Essential Duties And ResponsibilitiesAs the AI/ML developer, an ideal candidate will be part of a team to provide consultative, architectural, program, and engineering support for a federal customerDrive a big data approach to execute government requirements to manage and enrich data to gather new insights.Develop, train, and deploy advanced AI/ML models, including generative AI techniques like large language models (LLMs).Design and implement innovative AI solutions to address complex business challenges, such as natural language processing.Optimize model performance, ensuring accuracy, efficiency, and scalability.Develop, train, deploy and maintain user-friendly AI applications and interfaces, including chatbots, virtual assistants, and generative content tools.Collaborate with cross-functional teams to integrate AI solutions into existing systems and workflows.Stay up to date with the latest advancements in AI/ML and emerging technologies, such as generative AI and reinforcement learning.Conduct research and experiments to explore new AI techniques and applications, including prompt engineering, Advanced RAGs and fine-tuning LLMs.Ensure compliance with data privacy and security regulations, especially when dealing with sensitive data and generative AI outputs.Responsible for briefing the benefits and constraints of technology solutions to technology partners, stakeholders, team members, and senior levels of managementWork Experience5+ years of experience in the Information Technology field focusing on AI/ML engineering projects, MLOps/DevSecOps and technical architecture specifically.Experience in architecture & design, with a preference for 3 years of experience deploying production enterprise applications on-prem or on cloud.Experience with classification, forecasting, transformers, and generative models.Experience in data visualization using tools like Plotly and Matplotlib.Experience in large-scale, high-performance enterprise big data application deployment and solution architecture on complex heterogeneous environment.Experience with machine learning and generative AI frameworks.Experience with natural language processing techniques (e.g., text classification, language generation).Solid understanding of any of the cloud platforms (e.g., AWS, Azure, GCP) and deployment strategies.Job SkillsDatabase Knowledge: Knowledge of database systems (e.g., SQL, NoSQL) and data warehousing concepts.Generative AI Models: Proficiency in developing, deploying, and fine-tuning generative AI models, including large language models (LLMs).Multi-Agent / Agentic-AI Models: Proficiency in building Agentic-AI systems using tools such as LangChain Agents and Crew-AI.Cloud AI-ML Resource Knowledge: Knowledge of AWS SageMaker, Bedrock, Amazon Q, Amazon Elastic Inference.Programming Languages: Strong proficiency in programming languages such as Python, R, Java, and C/C++.Front-end Development: Proficiency in any front-end development technologies (e.g., React, Angular, Vue.js, HTML, CSS, JavaScript).Data Analytics: Expertise with libraries such as Pandas and NumPy for data manipulation and exploration.ML Frameworks: Proficiency in ML Modeling concepts and frameworks like Scikit-Learn, TensorFlow, Keras, PyTorch, and others.Data Preprocessing: Strong skills in data encoding, normalizing, and regularizing to prepare datasets for ML models.Deep Learning: Solid understanding of deep learning architectures such as CNNs (Convolutional Neural Networks), RNNs (Recurrent Neural Networks), LSTMs (Long Short-Term Memory networks), and GANs (Generative Adversarial Networks), with the ability to apply them to real-world data sets and problems.Anomaly Detection: Familiarity with anomaly detection techniques and deep learning models.Cloud Platforms: Solid understanding of cloud services, such as AWS, Azure, or GCP, and deployment strategies.EducationBachelor's degree in computer science, Information Technology Management or Engineering is preferred. Alternative work-related experience, Military Duty, and/or specialized or higher education may be substituted.Certificates, Licenses And RegistrationsThis federal program requires the candidates to be a United States Citizen.DHS Public Trust and/or DOD TS clearance is preferred.Qualified applicants may be subject to a security investigation and must meet minimum qualifications for access to classified information.Any related systems engineering, or related technical certifications are desired.AWS/Azure/GCP AI/ML certifications are preferred but not required.Communication SkillsExcellent verbal and written skills, ability to present proposals and performance data, comfortable interfacing all levels of organization.Enthusiastic, proactive, positive attitude with great listening skills, high integrity, and the ability to work effectively in a team environment.Ability to write clear and concise creative content in a highly confidential manner.Solid ability to interface, inspire and motivate at various levels of the organization.Ability to convey technical information to non-technical individuals.Demonstrated experience communicating effectively across internal and external organizations.TravelThis is a Hybrid position.Environmental RequirementsMainly sedentary; in an office environmentMay be required to lift up to ten (10) poundsFlexible in working extended hoursThe above statements are intended to describe the general nature and level of work being performed by the individual(s) assigned to this position. They are not intended to be an exhaustive list of all duties, responsibilities, and skills required. \", mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.02900988017658188),\n",
       " NodeWithScore(node=TextNode(id_='d15af210-bf4e-42c8-beb6-61f0e134026c', embedding=None, metadata={'id': '4208671629', 'title': 'Senior Deep Learning Engineer Intern - STWGB (April 2025 Start)', 'company': 'Flow', 'link': 'https://www.linkedin.com/jobs/view/4208671629/', 'keyword': 'Artificial Intelligence', 'location': 'Austin, TX'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"This position is ideal for individuals seeking a career in senior AI engineering and interested in working with a pioneering company in enterprise AI solutions.In this position, you will engage heavily in the development ofnatural language processing (NLP)models,large language models (LLMs)likeRAG,DistilBERT,BERT,RoBERTa, andLLaMA, as well asdeep reinforcement learningtechniques to create AI systems that learn, adapt, and evolve. You will be directly responsible for building AI pipelines, refining training methodologies, and implementing real-time solutions, ensuring they are secure, reliable, and optimized for performance in live cloud environments. In this role, you will be at the forefront of Flow's R&D initiatives, engaging in the entire AI development lifecycle. You’ll design, implement, and refine AI and deep learning models using state-of-the-art frameworks such asTensorFlow,PyTorch, and Keras, with a focus on Natural Language Processing (NLP), Large Language Models (LLMs) includingRAG, BERT, DistilBERT, RoBERTa, and LLaMA, and advanced neural architectures dedicated to Flow’s SaaS AI sales solutions. You’ll leverage these models in a cloud-based infrastructure, ensuring they are optimized, scalable, and capable of handling high-availability production loads.LLM-Specific Feature Optimization For Enhanced Contextual RelevanceCandidates must demonstrate extensive previous experience inadvanced feature engineeringfor optimizing large language models (LLMs) and Retrieval-Augmented Generation (RAG) architectures, specifically within high-dimensional vectorized environments. Expertise should encompass the following technical capabilities:Expert in engineering token embeddings, positional encodings, and contextual attention mechanisms tailored to transformer-based architectures (GPT, T5, BERT) within RAG frameworks. \", mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.028404512489927477),\n",
       " NodeWithScore(node=TextNode(id_='f19b6f18-d065-4a76-b387-64c533ba742f', embedding=None, metadata={'id': '4204519372', 'title': 'Data Scientist (AI & LLM Specialist) - to 240k + bonus + equity', 'company': 'Phaxis', 'link': 'https://www.linkedin.com/jobs/view/4204519372/', 'keyword': 'LLM Engineer', 'location': 'New York, NY'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Salary: $180k to $240k + bonus + equityHybrid positionWe are seeking a highly skilled Data Scientist with a focus on Large Language Models (LLMs) and Machine Learning (ML) to join our team. The ideal candidate will have deep experience in developing and deploying AI solutions, particularly using LLMs such as GPT-3, BERT, or similar technologies, to solve complex business problems. You will work closely with cross-functional teams to design, build, and deploy data-driven models that leverage advanced language processing techniques and traditional ML methods to drive innovation and business success.Key Responsibilities:Large Language Model (LLM) Development:Design, develop, and deploy LLM-based applications using technologies like GPT-3, BERT, or similar.Implement AI solutions using LLMs to automate and optimize business processes, such as text generation, summarization, sentiment analysis, and document classification.Fine-tune LLMs to improve model accuracy and efficiency for business-specific tasks.Machine Learning Model Development:Develop and deploy machine learning models using various algorithms (e.g., regression, classification, clustering) and deep learning techniques.Integrate LLM-based solutions with traditional machine learning models for complex, multi-faceted business problems.Algorithm Development and Optimization:Build and optimize algorithms to handle large-scale data and improve model performance.Leverage ML frameworks such as TensorFlow, PyTorch, and Scikit-learn to implement and fine-tune models, with a particular focus on language processing tasks.Python Programming and Software Development:Write clean, efficient, and scalable Python code for LLM and machine learning model development.Utilize libraries such as Pandas, NumPy, and SciPy to manipulate and analyze data, ensuring the smooth integration of models into production environments.Model Evaluation and Validation:Evaluate model performance using appropriate metrics (e.g., accuracy, precision, recall, F1 score) and ensure robustness, reliability, and generalizability of LLM and ML models.Continuously improve model outcomes by iterating on performance and fine-tuning for specific use cases.Collaboration and Reporting:Work closely with business leaders, engineers, and other stakeholders to translate business requirements into LLM and ML solutions.Present findings and model results to non-technical stakeholders, ensuring actionable insights.Create and maintain detailed documentation for processes, models, and methodologies.Requirements:Proven experience as a Data Scientist or Machine Learning Engineer with a focus on Large Language Models (LLMs).Strong proficiency in Python and experience with libraries such as Pandas, NumPy, TensorFlow, PyTorch, and Hugging Face Transformers.Experience in deploying and fine-tuning LLMs (e.g., GPT-3, BERT) for various NLP tasks such as text generation, summarization, sentiment analysis, and document processing.Solid understanding of machine learning algorithms and AI techniques, including supervised and unsupervised learning, deep learning, and reinforcement learning.Experience with data visualization tools (e.g., Matplotlib, Seaborn, Plotly) for presenting insights and findings.Experience with cloud platforms and big data technologies (e.g., AWS, Google Cloud, Hadoop, Spark) is a plus.Familiarity with version control systems like Git.Bachelor’s or Master’s degree in Computer Science, Data Science, Mathematics, or a related field.Preferred Skills:Experience with LLM Integration:Hands-on experience in building end-to-end pipelines for LLM-based solutions, integrating models into larger workflows, and deploying them in production environments.Familiarity with frameworks such as Hugging Face, OpenAI API, or similar tools for LLM development and deployment.Experience in advanced NLP tasks, including Named Entity Recognition (NER), sentiment analysis, text classification, and question answering.Strong communication skills with the ability to explain complex LLM and ML concepts to non-technical audiences.Familiarity with agile methodologies and working in a collaborative team environment.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.01639344262295082),\n",
       " NodeWithScore(node=Document(id_='3c9109f0-a4fc-4f61-a3a2-2aecd7e261c6', embedding=None, metadata={'id': '4137529872', 'title': 'Machine Learning (ML) Scientist', 'company': 'H2Ok Innovations', 'link': 'https://www.linkedin.com/jobs/view/4137529872/', 'keyword': 'MLOps', 'location': 'Somerville, MA'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"TensorFlow Lite) is a plusExperience building ML models with time-series or sequential data (such as NLP), especially for long time sequences and real-time processing scenarios. Experience working with sensor data is a plusFamiliarity with reinforcement learning (RL), computational graphs, and/or graph neural networks is a plus.Knowledgeable in techniques to optimize ML models for inference in compute-limited scenarios (i.e. model distillation, pruning, dimensionality reduction, feature selection, parallelization)Familiar deploying models for fast, efficient inference on compute accelerators (TPUs or NPUs).Proficient in designing, implementing, and maintaining robust ML pipelines for end-to-end model lifecycle management. Experience benchmarking multiple models is a plus.Familiar deploying models in containerized settings, such as Docker. Knowledge of Kubernetes and/or Docker Swarm is a plus. Familiar with SQL or similar database systems (such as MySQL, PostgreSQL, MongoDB)Proficient in Git or other version control systemsFamiliar with cloud platforms such as AWS, Azure, or Google CloudExperience working with LLMs/RAG is a plus, especially in building a company knowledgebase, chatbot, or for data analysis/summarization. Familiarity with Agile methodologies and experience in collaborative, cross-functional teamsAnalytical thinker with the ability to solve complex problems efficientlyExcellent communication skills to articulate technical issues, solutions, and progress effectivelyAdaptability to learn new technologies and adapt to evolving project requirementsStrong team player mindset, comfortable sharing knowledge and collaborating within a team environmentFamiliarity with Agile methodologies and experience in collaborative, cross-functional teamsAnalytical thinker with the ability to solve complex problems efficientlyMeticulous attention to detail in writing clean, maintainable code and designing robust database architecturesExcellent communication skills to articulate technical issues, solutions, and progress effectivelyAdaptability to learn new technologies and adapt to evolving project requirementsBenefitsDirect impact on product and cultureComprehensive benefits package including Medical, Dental, Vision, Life Insurance, Disability, Transportation benefit, Health and Wellness benefit, and more401k plan with employer matchingEquityCompetitive salary and bonus opportunitiesDynamic and inclusive work environmentOpportunities for growth and professional developmentAccess to Greentown Labs' extensive network of cleantech startupsLearn How We ThinkLearn about our startup journey: Our JourneyHow we're combating climate change: AI-Powered Climate TechA customer story: Ben & Jerry's uses H2Ok's precision automation to cut time & water usageWhy H2Ok Innovations?Impact:Work on cutting-edge AI and sensor tech that’s already transforming how factories use water, energy, and chemicals. Join a tight-knit, ambitious team where your contributions can reshape the industry.Growth:Join a fast-growing startup where you’ll have the opportunity to shape our content strategy. We value fostering extraordinary growth in our teammates.Innovative Culture:Work in a high-performance environment that values empowerment, creativity, ownership, autonomy, innovation, excellence, passion, and continuous growth.Sustainability Focus:Play a key role in promoting sustainability and Industry 4.0 advancements in manufacturing.Build the intelligence layer powering the next generation of industrial efficiency – with a team that moves fast and delivers real impact.At H2Ok Innovations, we’re committed to diversity, equity, and inclusion, and we encourage applicants from all backgrounds to apply. \", mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.016129032258064516),\n",
       " NodeWithScore(node=Document(id_='5d86fa6f-2598-418f-aad7-7e7a56046f4c', embedding=None, metadata={'id': '4194044158', 'title': 'AI/LLM Engineer', 'company': 'D2 Consulting', 'link': 'https://www.linkedin.com/jobs/view/4194044158/', 'keyword': 'LLM Engineer', 'location': 'Chantilly, VA'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='ACTIVE TS/SCI SECURITY CLEARANCE AND POLYGRAPH REQUIRED**Position Overview:D2 Consulting is seeking a highly skilledAI/LLM Engineerwith an activeTS/SCI clearance and CI polygraphto lead the design, deployment, and optimization of an on-premises Large Language Model (LLM) solution. This role involves architecting and implementing secure, scalable AI systems capable of ingesting, processing, and analyzing large datasets — including structured and unstructured data comprisingmillions of records.You will work alongside cross-functional teams supporting critical missions within the Intelligence Community, applying cutting-edge AI/ML techniques to drive insights and decision-making in secure environments.Key Responsibilities:Design and implement secure, on-premises LLM infrastructure and pipelines tailored to mission needsEvaluate, fine-tune, and deploy open-source or custom LLMs within air-gapped environmentsDevelop and manage data pipelines for ingesting and processing structured and unstructured datasets at scaleApply NLP, ML, and data science techniques to extract insights from massive datasets (millions+ records)Collaborate with analysts, engineers, and mission stakeholders to shape AI capabilities around operational requirementsEnsure compliance with security and data governance standards for classified environmentsMonitor model performance, implement updates, and optimize compute usageBasic Qualifications:Active TS/SCI clearance with CI Polygraph5+ years of experience in AI/ML engineering, data science, or software developmentHands-on experience deploying or fine-tuning LLMs (e.g., LLaMA, Mistral, GPT-NeoX, BERT, etc.)Experience with on-prem or air-gapped AI/ML deployments, including containerized or GPU-based environmentsStrong proficiency in Python and common ML/NLP libraries (e.g., Hugging Face Transformers, PyTorch, LangChain)Experience working with large datasets (millions of records), including ETL and data transformation pipelinesSolid understanding of system architecture, data privacy, and secure computing practicesPreferred Qualifications:Experience deploying quantized models for performance optimization (e.g., using llama.cpp, ggml, gguf)Familiarity with GPU server infrastructure (e.g., NVIDIA A100/RTX, CUDA) or multi-node compute setupsKnowledge of cloud-to-on-prem transition architecturesBackground in supporting Intelligence Community or DoD missionsWhy Join D2 Consulting?As aVeteran-Owned Small Business, D2 Consulting delivers enterprise IT services to the U.S. ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.015625),\n",
       " NodeWithScore(node=TextNode(id_='7f8989b8-48fe-4698-bcd9-0516351671fd', embedding=None, metadata={'id': '4196412518', 'title': 'Senior Machine Learning Engineer', 'company': 'IntelePeer', 'link': 'https://www.linkedin.com/jobs/view/4196412518/', 'keyword': 'Machine Learning', 'location': 'Dania, FL'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Our Conversational AI Platform instantly improves your customers’ communications experience. IntelePeer provides industry leading time-to-value with Agentic AI solutions that work seamlessly with your infrastructure. Our no-code templates, low-code, co-creation, and developer API options provide you with simple, easy-to-use tools that can be utilized by anyone.What we are looking for:As a Senior Machine Learning Engineer with a focus on NLP, you will lead the design, development, and optimization of state-of-the-art transformer-based models. You will play a key role in the full ML lifecycle, including data preprocessing, model building, fine-tuning, transfer learning, evaluation, and deployment. You will also be responsible for ensuring model performance and fairness by addressing biases and ensuring ethical AI practices.Key Responsibilities:Design, implement, and optimize NLP models with a strong focus on transformer-based architectures (e.g., BERT, GPT, T5).Build and fine-tune models for a variety of NLP tasks, such as text classification, sentiment analysis, named entity recognition (NER), machine translation, and question answering.Develop and implement strategies for transfer learning to leverage pre-trained models effectively in various domains.Lead the evaluation of model performance using metrics such as accuracy, precision, recall, and F1 scores, while ensuring robustness and fairness in predictions.Conduct research to detect, mitigate, and manage biases in ML models, ensuring ethical and transparent AI solutions.Optimize model inference and ensure low-latency performance in real-time applications.Mentor junior engineers and provide technical leadership in ML/NLP best practices.Stay current with the latest advancements in NLP, transformer architectures, and ML techniques to drive continuous improvement.Requirements:Proven expertise in NLP with at least 5 years of hands-on experience in building and deploying NLP models.Strong knowledge of transformer-based models (e.g., BERT, GPT, RoBERTa, T5, etc.) ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.015625)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c852337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
